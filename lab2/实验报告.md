
# 练习1

分析函数这4个函数前，先列举2个常用的结构体
```cpp
typedef struct {
    list_entry_t free_list;         // the list header
    unsigned int nr_free;           // number of free pages in this free list
} free_area_t;
struct Page {
    int ref;                        // page frame's reference counter
    uint64_t flags;                 // array of flags that describe the status of the page frame
    unsigned int property;          // the num of free block, used in first fit pm manager
    list_entry_t page_link;         // free list link
};
```
在`default_pmm.c`中, `free_list`和`nr_free`分别被设置为`free_area_t`的成员变量的宏定义，其实就是拿出来了作为全局变量，一个是链表头，一个是空闲块的数量。

这里有一个缺陷就是只有一个双链表来维护，这样的话很多不同大小的块就会放在一个链表里面，导致查找的时候效率低下。

`Page`结构体中，`ref`是引用计数器，`flags`是描述页帧状态的数组，`property`是空闲块的数量，`page_link`是空闲链表的链接。

得到的地址空间图类似于：
```
虚拟地址 (VA)                                         物理地址 (PA)
高地址 ^                                                 高地址 ^
      |                                                        |
      +-----------------------------------------+              +-----------------------------------------+
      |                                         |              |  物理内存最高地址                       |
      +-----------------------------------------+              +-----------------------------------------+
      | (可能的内存碎片, 大小不足一页)          |              
      +=========================================+ <--- mem_end (向下对齐, 可用内存的物理上界)
      |                                         |
      |                                         |
      |    这部分物理内存由 free_list 管理      |
      |    (初始状态为一个巨大的空闲块)         |
      |                                         |
      +=========================================+ <--- mem_begin (向上对齐, 可用内存的物理下界)
      | (可能的对齐“空隙”, 被舍弃)             |
      +-----------------------------------------+ <--- freemem (紧跟在 pages 数组之后, 未对齐)
      |                                         |
      |      pages 数组 (物理内存的“账本”)      |
      |                                         |
      +-----------------------------------------+
      |                                         |
      +------------------.----------------------+
      | KERNBASE + ...   `end` 符号 (虚拟地址)  |
      |                  +----------------------+
      | 内核镜像         | .bss 段              |
      | (Kernel Image)   +----------------------+
      |                  | .data/.sdata 段      |
      | 已被占用         +----------------------+
      |                  | .rodata 段           |
      |                  +----------------------+
      |                  | .text 段 (代码)      |
      +------------------'----------------------+
      | KERNBASE (0xFFFFFFFFC0200000)          | <----------> | 内核加载的物理基地址 (如 0x80200000)
      +-----------------------------------------+              +-----------------------------------------+
      |                                         |              | (OpenSBI 固件区域)                      |
      |                                         |              +-----------------------------------------+
      |                                         |              | DRAM_BASE (物理内存起点, 0x80000000)    |
低地址 v                                                 低地址 v
```



### default_init()
```cpp
static inline void list_init(list_entry_t *elm) {
    elm->prev = elm->next = elm;
}

static void default_init(void) {
    list_init(&free_list);
    nr_free = 0;
}
```
作用是“创建账本”。这是 PMM 的第一个动作，负责创建并初始化一个空的 `free_area_t `管理结构。

调用 `list_init(&free_list)`来初始化全局的双向链表头，使其 `next` 和 `prev` 指针都指向自己，形成一个空的循环链表。

设置` nr_free = 0`，将全局空闲页总数清零。

### default_init_memmap()
这个函数是由`pmm.c`中的`page_init()`使用
```cpp
if (freemem < mem_end) {
        init_memmap(pa2page(mem_begin), (mem_end - mem_begin) / PGSIZE);
    }
```
函数头是这样的：
```cpp
static void default_init_memmap(struct Page *base, size_t n) 
```
和在一起看就是在`base`地址处初始化`n`个页，并将其加入到空闲链表中，这里使用的base就是`pa2page(mem_begin)`。

**作用就是：** 在 `page_init()` 确定了内核本身和 `pages` 数组占用的空间后，会把剩余的所有可用物理内存作为一个巨大的初始块，调用此函数将其“注册”到 PMM 中。

#### 具体流程

- **准备页：** 遍历从 `base(pa2page(mem_begin))` 开始的 `n` 个 `Page` 结构体，清空它们的 `flags` 和 `ref` 计数，确保它们处于干净状态。
```cpp
struct Page *p = base;
for (; p != base + n; p ++) {
        assert(PageReserved(p));
        p->flags = p->property = 0;
        set_page_ref(p, 0);
}
```

- **标记首页**：设置首页 `base->property = n`，记录下这个巨大空闲块的总大小。同时设置 `base` 的 `PG_property` 标志位，正式声明它是一个空闲块的“代表”。
```cpp
base->property = n;
```

- **更新总数：** `nr_free += n`，将这 n 个页加入到全局空闲页总数中。
```cpp
nr_free += n;
```

- **插入链表**：将 `base` 的 `page_link` 节点插入到全局的 `free_list` 中。为了方便后续的合并操作，插入时必须保持链表按物理地址从低到高排序。


PMM 的 free_list 中现在有了一个（或多个）节点，代表着大块的初始空闲内存。nr_free 也更新为系统初始的可用页总数。至此，初始化完成。

### default_alloc_pages()
初始化完成后，内核通过调用 `alloc_pages` 和 `free_pages` 来动态管理内存。

**作用：** 按需分配。这是向 PMM 申请 n 个连续物理页的核心函数。

#### 具体流程

- **快速检查：** 首先检查请求的 n 是否大于总空闲页数 `nr_free`，如果大于，则直接返回 `NULL。`
```cpp
if (n > nr_free) {return NULL;}
```
- **首次适应查找**：从 `free_list` 的头部开始，依次遍历每一个空闲块（由其首页代表）。
```cpp
list_entry_t *le = &free_list;
while ((le = list_next(le)) != &free_list) {
        struct Page *p = le2page(le, page_link);
        if (p->property >= n) {
            page = p;
            break;
        }
    }
```

- **检查大小：** 对于每个块 p，检查 `p->property >= n` 是否成立。

- **找到与分割：** 一旦找到第一个满足条件的块 p，就停止搜索 `-->` 将 p 从 `free_list` 中移除 `-->` 如果 p->property > n（找到的块比需要的大），则执行分割操作:
```cpp
if (page->property > n) {
    struct Page *p = page + n;
    p->property = page->property - n;
    SetPageProperty(p);
    list_add(prev, &(p->page_link));
}
```

- **更新与返回：** `nr_free -= n`，更新全局空闲页总数。清除被分配出去的首页 p 的 PG_property 标志，因为它不再是空闲块了。返回首页指针 p，如果没找到就返回`NULL`。


### default_free_pages()

**作用：** 将一块不再使用的内存归还给 PMM。

#### 具体流程

- **准备与标记** ：将被释放的 n 个页的状态重置（清 flags，ref=0），并将首页 `base` 的 `property` 设为 n，标记为新的空闲块。在代码中就是一个for循环
```cpp
struct Page *p = base;
for (; p != base + n; p ++) {
    assert(!PageReserved(p) && !PageProperty(p));
    p->flags = 0;
    set_page_ref(p, 0);
}
```
- **插入链表：** 像 `default_init_memmap` 一样，将 `base` 插入到 `free_list` 中，保持地址有序。并更新总数：nr_free += n。

- **合并** ：这是最关键的一步，为了防止内存碎片化。
这里有两种，先向前合并，然后向后合并，这里的检查比较简单，只是检查地址是否连续，如果连续就合并。具体到代码中就是：
```cpp
list_entry_t* le = list_prev(&(base->page_link)); //前向合并
......
p = le2page(le, page_link);
if (p + p->property == base)
......

le = list_next(&(base->page_link)); //后向合并
......
p = le2page(le, page_link);
if (base + base->property == p)
......
```

结果就是释放的内存被重新纳入管理，并尽可能地与已有的空闲块合并，形成更大的连续空闲区。

`make qemu`之后
```c
PMP0: 0x0000000080000000-0x000000008001ffff (A)
PMP1: 0x0000000000000000-0xffffffffffffffff (A,R,W,X)
DTB Init
HartID: 0
DTB Address: 0x82200000
Physical Memory from DTB:
  Base: 0x0000000080000000
  Size: 0x0000000008000000 (128 MB)
  End:  0x0000000087ffffff
DTB init completed
(THU.CST) os is loading ...
Special kernel symbols:
  entry  0xffffffffc02000d6 (virtual)
  etext  0xffffffffc0201716 (virtual)
  edata  0xffffffffc0206018 (virtual)
  end    0xffffffffc0206078 (virtual)
Kernel executable memory footprint: 24KB
memory management: default_pmm_manager
physcial memory map:
  memory: 0x0000000008000000, [0x0000000080000000, 0x0000000087ffffff].
check_alloc_page() succeeded!
satp virtual address: 0xffffffffc0205000
satp physical address: 0x0000000080205000
```

内核占用了24KB。

物理内存探测结果：
```
physcial memory map:
  memory: 0x0000000008000000, [0x0000000080000000, 0x0000000087ffffff].
```
起点是0x0000000008000000，范围是 [0x0000000080000000, 0x0000000087ffffff]

三级页表（boot_page_table_sv39）地址
```
satp virtual address: 0xffffffffc0205000
satp physical address: 0x0000000080205000
```

--------------------------------
# 练习2:实现best_fit

`make qemu`:
```c
PMP0: 0x0000000080000000-0x000000008001ffff (A)
PMP1: 0x0000000000000000-0xffffffffffffffff (A,R,W,X)
DTB Init
HartID: 0
DTB Address: 0x82200000
Physical Memory from DTB:
  Base: 0x0000000080000000
  Size: 0x0000000008000000 (128 MB)
  End:  0x0000000087ffffff
DTB init completed
(THU.CST) os is loading ...
Special kernel symbols:
  entry  0xffffffffc02000d6 (virtual)
  etext  0xffffffffc0201656 (virtual)
  edata  0xffffffffc0205018 (virtual)
  end    0xffffffffc0205078 (virtual)
Kernel executable memory footprint: 20KB
memory management: best_fit_pmm_manager
physcial memory map:
  memory: 0x0000000008000000, [0x0000000080000000, 0x0000000087ffffff].
check_alloc_page() succeeded!
satp virtual address: 0xffffffffc0204000
satp physical address: 0x0000000080204000
```
最后显示check_alloc_page() succeeded!应该就是成功了。

`make grade` :
```
>>>>>>>>>> here_make>>>>>>>>>>>
gmake[1]: 进入目录“/home/jay/桌面/labcode/lab2/best_fit” + cc kern/init/entry.S + cc kern/init/init.c + cc kern/libs/stdio.c + cc kern/debug/panic.c + cc kern/driver/console.c + cc kern/driver/dtb.c + cc kern/mm/best_fit_pmm.c + cc kern/mm/default_pmm.c + cc kern/mm/pmm.c + cc libs/printfmt.c + cc libs/readline.c + cc libs/sbi.c + cc libs/string.c + ld bin/kernel riscv64-unknown-elf-objcopy bin/kernel --strip-all -O binary bin/ucore.img gmake[1]: 离开目录“/home/jay/桌面/labcode/lab2/best_fit”
>>>>>>>>>> here_make>>>>>>>>>>>
<<<<<<<<<<<<<<< here_run_qemu <<<<<<<<<<<<<<<<<<
try to run qemu
qemu pid=4082
<<<<<<<<<<<<<<< here_run_check <<<<<<<<<<<<<<<<<<
  -check physical_memory_map_information:    OK
  -check_best_fit:                           OK
Total Score: 25/25
```

修改的地方其实不多，大部分逻辑和`first_fit`差不多，主要的区别还是分配内存的函数的逻辑不一样，其实理解了`first_fit`的代码，写`best_fit`就很简单。

**分配内存的函数修改部分**
```cpp
    int best_n = -1;
    struct Page *best_page = NULL;


    while ((le = list_next(le)) != &free_list) {
        struct Page *p = le2page(le, page_link);
        if (p->property >= n) 
        {
            if(best_n == -1 || best_n > p->property)
            {
                best_n = p->property;
                best_page = p;
            }
        }
    }
    page = best_page;
```
当时写的时候没有注意到代码里面已经给了`min_size`变量，不过无伤大雅，我自己定义一个`best_n`变量来记录最适合的空闲块的大小，然后在循环里面找到最适合的空闲块，并更新`best_page`。初始化`best_n = -1 `是用来标记是否分配了一个。然后就是从前往后依次遍历，时间复杂度固定是`O(n)`,n是指总的空闲页数。

每次循环，如果找到一个满足的，看看是否可以更小，如果是更小的话，就更新`best_page` 和 `best_n`。

代码中和 `first_fit` 不一样的地方就上面，其他都是一样的，管理空闲链也是只用了一个链表。

best_fit 我想过优化，其实这里的瓶颈是在于查找最佳空闲块的那个循环。可以转化为平衡树来查找，但是，实现起来就比较麻烦，插入和删除比较简单，就是释放之后，合并空闲页的时候会不好合并，比如说我们平衡树中的Node是这样定义的话：
```cpp
struct Node
{
    Page *page;
    Node *left, *right;
}
```
查找的时候根据page->property来查找。但是在合并的时候会有困难，比如说要和前面的空闲块合并，我得先在平衡树里面找到这个页，可是这里平衡树查找是根据property，而不是页号，因此就很难在平衡树里面找到这个页并将其删除来进行合并。

如果优化这个策略的话，可以采用下面的那些策略。毕竟只是在一个策略里面绕弯子不如换一个策略来实现更简单。

--------------------------------


# 扩展练习Challenge：buddy system（伙伴系统）分配算法（需要编程）
**设计思想**
我们参考伙伴分配器的一个极简实现，基于伙伴分配算法的物理内存管理器采用完全二叉树结构管理内存块，通过将内存划分为2的幂次方大小的块来实现高效分配。该系统使用二叉树的每个节点记录对应内存区域的最大可用连续大小，分配时从根节点向下搜索最佳匹配块并标记为占用，释放时通过向上合并伙伴块来减少内存碎片。利用位运算快速判断2的幂和计算伙伴关系，确保分配和释放操作在对数时间内完成，同时将管理结构嵌入被管理内存末尾以最小化空间开销，为操作系统提供了高效可靠的连续内存管理能力。

内存布局：
```
+-------------------+ 低地址
|   已用内存区域    |
+-------------------+
|                   |
|   伙伴系统管理     |
|   的物理页面       |
|                   |
+-------------------+
|  伙伴系统结构体    | ← buddy_sys
| (包含二叉树数组)   |
+-------------------+ 高地址
```

刚开始编写代码时，我在头文件中使用了math.h，但在编译时发现在uCore的内核环境中不能使用标准C库的math.h，需要移除对math.h的依赖，自己实现相关的数学函数。

**预备工作**
1. 首先我们建立伙伴系统结构体，包含size和longest：
size是管理的总页面数；
longest表示使用完全二叉树记录每个节点的最大可用连续块大小。
```c
struct buddy {
    unsigned size;           // 管理的总页面数（必须是2的幂）
    unsigned longest[0];     // 柔性数组，记录每个节点的最大可用块大小
};
```
2. 接着是全局变量:
伙伴系统结构体指针：buddy_sys
管理内存的基地址：buddy_base
空闲区域管理：free_area
```c
static struct buddy *buddy_sys = NULL;
static struct Page *buddy_base = NULL;
static free_area_t free_area;
```
3. 核心宏定义
```c
#define LEFT_LEAF(index)     ((index) * 2 + 1)      // 左子节点索引
#define RIGHT_LEAF(index)    ((index) * 2 + 2)      // 右子节点索引
#define PARENT(index)        (((index) + 1) / 2 - 1) // 父节点索引

#define IS_POWER_OF_2(x)     (!((x) & ((x) - 1)))   // 判断是否为2的幂
#define MAX(a, b)           ((a) > (b) ? (a) : (b)) // 最大值
```
**关键函数详解**
1. 初始化函数
- buddy_init()：
初始化空闲链表
重置全局变量
```c
static void
buddy_init(void) {
    list_init(&free_list);
    nr_free = 0;
    buddy_sys = NULL;
    buddy_base = NULL;
}
```
- buddy_init_memmap(struct Page *base, size_t n)：
1） 初始化物理页面属性
2） 计算实际管理的页面数（调整为2的幂）
3） 在内存末尾分配伙伴系统结构体
4） 初始化二叉树节点：
   - 叶子节点：大小为1（单页）
   - 内部节点：左右子节点大小之和
```c
static void
buddy_init_memmap(struct Page *base, size_t n) {
    assert(n > 0);
    cprintf("buddy_init_memmap: 初始化 %lu 页内存\n", n);
    
    // 初始化页面
    struct Page *p = base;
    for (; p != base + n; p++) {
        assert(PageReserved(p));
        p->flags = 0;
        SetPageProperty(p);
        p->property = 0;
        set_page_ref(p, 0);
    }
    
    buddy_base = base;
    
    // 计算实际管理的页面数（调整为2的幂）
    unsigned actual_size = fixsize(n);
    cprintf("buddy_init_memmap: 实际管理 %u 页（调整为2的幂）\n", actual_size);
    
    // 分配伙伴系统结构体（包含位图）
    // 我们将伙伴系统结构体放在管理内存的末尾
    size_t buddy_size = sizeof(struct buddy) + sizeof(unsigned) * (2 * actual_size - 1);
    size_t buddy_pages = (buddy_size + PGSIZE - 1) / PGSIZE;
    
    cprintf("buddy_init_memmap: 伙伴系统需要 %lu 字节，%lu 页\n", buddy_size, buddy_pages);
    
    // 确保有足够空间存放伙伴系统结构体
    if (actual_size < buddy_pages) {
        panic("buddy_init_memmap: 内存不足存放伙伴系统结构体");
    }
    
    // 伙伴系统结构体放在管理内存的末尾
    uintptr_t buddy_addr = (uintptr_t)(base + actual_size - buddy_pages);
    buddy_sys = (struct buddy *)buddy_addr;
    
    buddy_sys->size = actual_size - buddy_pages;  // 实际可用的页面数
    nr_free = buddy_sys->size;
    
    cprintf("buddy_init_memmap: 伙伴系统位于 %p，管理 %u 页\n", buddy_sys, buddy_sys->size);
    
    // 初始化二叉树节点 - 修复初始化逻辑
    for (int i = 0; i < 2 * buddy_sys->size - 1; ++i) {
        buddy_sys->longest[i] = 0;
    }
    
    // 自底向上初始化
    for (int i = 0; i < buddy_sys->size; i++) {
        int index = i + buddy_sys->size - 1;
        buddy_sys->longest[index] = 1;
    }
    
    for (int i = buddy_sys->size - 2; i >= 0; i--) {
        buddy_sys->longest[i] = buddy_sys->longest[LEFT_LEAF(i)] + buddy_sys->longest[RIGHT_LEAF(i)];
    }
    
    cprintf("buddy_init_memmap: 初始化完成，空闲页面数 = %lu\n", nr_free);
    cprintf("buddy_init_memmap: 根节点大小 = %u\n", buddy_sys->longest[0]);
}
```

**分配内存**
我们编写函数buddy_alloc_pages(size_t n)来进行内存的分配。
算法流程：
- 调整大小：将请求大小调整为2的幂
- 检查可用性：根节点是否有足够空间
- 搜索合适节点：从根节点开始向下搜索；优先选择左子树（如果足够大）
- 分配标记：将找到的节点标记为已分配（longest=0）
- 计算偏移：确定对应的物理页面位置
- 更新祖先节点：自底向上更新父节点的最大可用大小

搜索示例：
```c
树结构：
      [8]
     /   \
   [4]   [4]
  /   \   /  \
[2]  [2][2]  [2]

分配2页：从根节点[8]→左子节点[4]→满足条件
```

代码展示：
```c
static struct Page *
buddy_alloc_pages(size_t n) {
    assert(n > 0);
    
    if (n > nr_free || buddy_sys == NULL) {
        cprintf("buddy_alloc_pages: 没有足够内存或伙伴系统未初始化\n");
        return NULL;
    }
    
    // 调整请求大小为2的幂
    unsigned alloc_size = fixsize(n);
    
    cprintf("buddy_alloc_pages: 请求 %lu 页，实际分配 %u 页\n", n, alloc_size);
    
    // 检查根节点是否有足够空间
    if (buddy_sys->longest[0] < alloc_size) {
        cprintf("buddy_alloc_pages: 没有足够连续空间，最大可用 %u 页\n", buddy_sys->longest[0]);
        return NULL;
    }
    
    // 搜索合适的节点
    unsigned index = 0;
    unsigned node_size = buddy_sys->size;
    
    // 向下搜索到合适的节点
    while (node_size > alloc_size) {
        unsigned left = LEFT_LEAF(index);
        unsigned right = RIGHT_LEAF(index);
        
        if (buddy_sys->longest[left] >= alloc_size) {
            index = left;
        } else {
            index = right;
        }
        node_size /= 2;
    }
    
    // 检查最终节点是否合适
    if (buddy_sys->longest[index] < alloc_size) {
        cprintf("buddy_alloc_pages: 搜索失败，节点 %u 大小 %u < 需求 %u\n", 
                index, buddy_sys->longest[index], alloc_size);
        return NULL;
    }
    
    cprintf("buddy_alloc_pages: 在节点 %u 分配 %u 页\n", index, alloc_size);
    
    // 标记节点为已分配
    unsigned allocated = buddy_sys->longest[index];
    buddy_sys->longest[index] = 0;
    
    // 计算偏移 - 简化方法
    unsigned offset = 0;
    unsigned temp_index = index;
    unsigned temp_size = alloc_size;
    
    // 从叶子节点向上计算偏移
    if (index >= buddy_sys->size - 1) {
        // 叶子节点
        offset = index - (buddy_sys->size - 1);
    } else {
        // 内部节点，需要计算
        while (temp_index > 0) {
            if (temp_index % 2 == 0) {
                // 右孩子，需要加上左子树的大小
                offset += temp_size;
            }
            temp_index = PARENT(temp_index);
            temp_size *= 2;
        }
    }
    
    cprintf("buddy_alloc_pages: 偏移 %u\n", offset);
    
    // 检查偏移是否有效
    if (offset >= buddy_sys->size) {
        cprintf("buddy_alloc_pages: 错误！偏移 %u 超出范围 [0, %u)\n", offset, buddy_sys->size);
        return NULL;
    }
    
    // 向上更新祖先节点
    temp_index = index;
    while (temp_index > 0) {
        temp_index = PARENT(temp_index);
        buddy_sys->longest[temp_index] = 
            MAX(buddy_sys->longest[LEFT_LEAF(temp_index)], 
                buddy_sys->longest[RIGHT_LEAF(temp_index)]);
    }
    
    // 获取对应的物理页面
    struct Page *page = &buddy_base[offset];
    
    // 设置页面属性
    for (unsigned i = 0; i < alloc_size; i++) {
        ClearPageProperty(&page[i]);
        set_page_ref(&page[i], 1);
    }
    
    nr_free -= alloc_size;
    cprintf("buddy_alloc_pages: 分配完成，剩余空闲 %lu\n", nr_free);
    
    return page;
}
```
**释放内存**
我们编写函数buddy_free_pages(struct Page *base, size_t n)来进行内存的释放：
算法流程：
- 计算偏移：通过页面指针计算在二叉树中的位置
- 恢复节点：将对应叶子节点标记为可用
- 合并伙伴：自底向上检查并合并，如果两个伙伴节点都完全空闲且大小相同，则合并为更大的连续块。

合并示例：
```c
释放后合并：
     [0]           [2]           [4]
    /   \   →     /   \   →     /   \
  [1]   [1]     [2]   [2]     [4]   [2]
```
代码展示：
```c
static void
buddy_free_pages(struct Page *base, size_t n) {
    assert(n > 0);
    assert(base != NULL);
    assert(buddy_sys != NULL);
    
    size_t offset = base - buddy_base;
    
    // 调整释放大小为2的幂
    unsigned free_size = fixsize(n);
    
    cprintf("buddy_free_pages: 释放 %lu 页，实际释放 %u 页，偏移 %lu\n", 
            n, free_size, offset);
    
    // 检查偏移是否有效
    if (offset >= buddy_sys->size) {
        panic("buddy_free_pages: 偏移超出范围");
    }
    
    // 计算对应的节点索引
    unsigned index = offset + buddy_sys->size - 1;
    
    cprintf("buddy_free_pages: 找到节点 %u，对应偏移 %lu\n", index, offset);
    
    // 恢复节点大小
    buddy_sys->longest[index] = free_size;
    
    // 向上合并伙伴块
    unsigned temp_index = index;
    while (temp_index > 0) {
        temp_index = PARENT(temp_index);
        unsigned left = LEFT_LEAF(temp_index);
        unsigned right = RIGHT_LEAF(temp_index);
        
        if (buddy_sys->longest[left] > 0 && buddy_sys->longest[right] > 0 &&
            buddy_sys->longest[left] == buddy_sys->longest[right]) {
            // 可以合并
            buddy_sys->longest[temp_index] = buddy_sys->longest[left] + buddy_sys->longest[right];
            cprintf("buddy_free_pages: 合并节点 %u，大小 %u\n", temp_index, buddy_sys->longest[temp_index]);
        } else {
            // 不能合并，取最大值
            buddy_sys->longest[temp_index] = MAX(buddy_sys->longest[left], buddy_sys->longest[right]);
            cprintf("buddy_free_pages: 更新节点 %u，大小 %u\n", temp_index, buddy_sys->longest[temp_index]);
            break;
        }
    }
    
    // 设置页面属性
    for (unsigned i = 0; i < free_size; i++) {
        SetPageProperty(&base[i]);
        set_page_ref(&base[i], 0);
    }
    
    nr_free += free_size;
    cprintf("buddy_free_pages: 释放完成，剩余空闲 %lu\n", nr_free);
}
```

**辅助函数 fixsize(unsigned size)**
功能：将任意大小调整为不小于它的最小2的幂
例如：3→4, 5→8, 9→16
```c
// 将size调整为2的幂
static unsigned fixsize(unsigned size) {
    if (size == 0) return 1;
    unsigned result = 1;
    while (result < size) {
        result <<= 1;
    }
    return result;
}
```

**测试**
编写函数对上述函数功能进行测试，我们进行了单页分配与释放测试、多页分配与释放测试，测试函数如下：
```c
static void
basic_buddy_check(void) {
    cprintf("=== 开始伙伴系统基本检查 ===\n");
    
    // 单页分配测试
    cprintf("测试1: 单页分配...\n");
    struct Page *p0 = alloc_pages(1);
    struct Page *p1 = alloc_pages(1);
    struct Page *p2 = alloc_pages(1);
    
    if (p0 != NULL && p1 != NULL && p2 != NULL) {
        cprintf("页面分配成功: p0=%p, p1=%p, p2=%p\n", p0, p1, p2);
        if (p0 != p1 && p0 != p2 && p1 != p2) {
            cprintf("单页分配测试通过\n");
        } else {
            panic("分配了重复的页面");
        }
    } else {
        panic("单页分配失败");
    }
    
    // 先释放单页，为多页分配腾出连续空间
    cprintf("释放单页为多页分配做准备...\n");
    free_pages(p0, 1);
    free_pages(p1, 1);
    free_pages(p2, 1);
    
    // 多页分配测试 - 从较小的开始
    cprintf("测试2: 多页分配...\n");
    struct Page *p2pages = alloc_pages(2);   // 2页
    if (p2pages != NULL) {
        cprintf("2页分配成功: %p\n", p2pages);
        free_pages(p2pages, 2);
    }
    
    struct Page *p4 = alloc_pages(4);   // 4页
    if (p4 != NULL) {
        cprintf("4页分配成功: %p\n", p4);
        free_pages(p4, 4);
    }
    
    struct Page *p8 = alloc_pages(8);   // 8页
    if (p8 != NULL) {
        cprintf("8页分配成功: %p\n", p8);
        free_pages(p8, 8);
        cprintf("多页分配测试通过\n");
    } else {
        cprintf("8页分配失败，但较小分配成功\n");
    }
    
    cprintf("=== 伙伴系统基本检查完成 ===\n");
}
```

**测试结果**
```c
Platform Name          : QEMU Virt Machine
Platform HART Features : RV64ACDFIMSU
Platform Max HARTs     : 8
Current Hart           : 0
Firmware Base          : 0x80000000
Firmware Size          : 112 KB
Runtime SBI Version    : 0.1

PMP0: 0x0000000080000000-0x000000008001ffff (A)
PMP1: 0x0000000000000000-0xffffffffffffffff (A,R,W,X)
DTB Init
HartID: 0
DTB Address: 0x82200000
Physical Memory from DTB:
  Base: 0x0000000080000000
  Size: 0x0000000008000000 (128 MB)
  End:  0x0000000087ffffff
DTB init completed
(THU.CST) os is loading ...
Special kernel symbols:
  entry  0xffffffffc02000d8 (virtual)
  etext  0xffffffffc020166a (virtual)
  edata  0xffffffffc0206018 (virtual)
  end    0xffffffffc0206088 (virtual)
Kernel executable memory footprint: 24KB
memory management: buddy_pmm_manager
physcial memory map:
  memory: 0x0000000008000000, [0x0000000080000000, 0x0000000087ffffff].
buddy_init_memmap: 初始化 31929 页内存
buddy_init_memmap: 实际管理 32768 页（调整为2的幂）
buddy_init_memmap: 伙伴系统需要 262144 字节，64 页
buddy_init_memmap: 伙伴系统位于 0xffffffffc034e918，管理 32704 页
buddy_init_memmap: 初始化完成，空闲页面数 = 32704
buddy_init_memmap: 根节点大小 = 32704
=== 开始伙伴系统基本检查 ===
测试1: 单页分配...
buddy_alloc_pages: 请求 1 页，实际分配 1 页
buddy_alloc_pages: 在节点 16383 分配 1 页
buddy_alloc_pages: 偏移 0
buddy_alloc_pages: 分配完成，剩余空闲 32703
buddy_alloc_pages: 请求 1 页，实际分配 1 页
buddy_alloc_pages: 在节点 16384 分配 1 页
buddy_alloc_pages: 偏移 1
buddy_alloc_pages: 分配完成，剩余空闲 32702
buddy_alloc_pages: 请求 1 页，实际分配 1 页
buddy_alloc_pages: 在节点 16385 分配 1 页
buddy_alloc_pages: 偏移 2
buddy_alloc_pages: 分配完成，剩余空闲 32701
页面分配成功: p0=0xffffffffc020f318, p1=0xffffffffc020f340, p2=0xffffffffc020f368
单页分配测试通过
释放单页为多页分配做准备...
buddy_free_pages: 释放 1 页，实际释放 1 页，偏移 0
buddy_free_pages: 找到节点 32703，对应偏移 0
buddy_free_pages: 合并节点 16351，大小 2
buddy_free_pages: 合并节点 8175，大小 4
buddy_free_pages: 合并节点 4087，大小 8
buddy_free_pages: 合并节点 2043，大小 16
buddy_free_pages: 合并节点 1021，大小 32
buddy_free_pages: 合并节点 510，大小 64
buddy_free_pages: 更新节点 254，大小 128
buddy_free_pages: 释放完成，剩余空闲 32702
buddy_free_pages: 释放 1 页，实际释放 1 页，偏移 1
buddy_free_pages: 找到节点 32704，对应偏移 1
buddy_free_pages: 合并节点 16351，大小 2
buddy_free_pages: 合并节点 8175，大小 4
buddy_free_pages: 合并节点 4087，大小 8
buddy_free_pages: 合并节点 2043，大小 16
buddy_free_pages: 合并节点 1021，大小 32
buddy_free_pages: 合并节点 510，大小 64
buddy_free_pages: 更新节点 254，大小 128
buddy_free_pages: 释放完成，剩余空闲 32703
buddy_free_pages: 释放 1 页，实际释放 1 页，偏移 2
buddy_free_pages: 找到节点 32705，对应偏移 2
buddy_free_pages: 合并节点 16352，大小 2
buddy_free_pages: 合并节点 8175，大小 4
buddy_free_pages: 合并节点 4087，大小 8
buddy_free_pages: 合并节点 2043，大小 16
buddy_free_pages: 合并节点 1021，大小 32
buddy_free_pages: 合并节点 510，大小 64
buddy_free_pages: 更新节点 254，大小 128
buddy_free_pages: 释放完成，剩余空闲 32704
测试2: 多页分配...
buddy_alloc_pages: 请求 2 页，实际分配 2 页
buddy_alloc_pages: 在节点 16386 分配 2 页
buddy_alloc_pages: 偏移 6
buddy_alloc_pages: 分配完成，剩余空闲 32702
2页分配成功: 0xffffffffc020f408
buddy_free_pages: 释放 2 页，实际释放 2 页，偏移 6
buddy_free_pages: 找到节点 32709，对应偏移 6
buddy_free_pages: 更新节点 16354，大小 2
buddy_free_pages: 释放完成，剩余空闲 32704
buddy_alloc_pages: 请求 4 页，实际分配 4 页
buddy_alloc_pages: 在节点 8193 分配 4 页
buddy_alloc_pages: 偏移 8
buddy_alloc_pages: 分配完成，剩余空闲 32700
4页分配成功: 0xffffffffc020f458
buddy_free_pages: 释放 4 页，实际释放 4 页，偏移 8
buddy_free_pages: 找到节点 32711，对应偏移 8
buddy_free_pages: 更新节点 16355，大小 4
buddy_free_pages: 释放完成，剩余空闲 32704
buddy_alloc_pages: 请求 8 页，实际分配 8 页
buddy_alloc_pages: 在节点 4097 分配 8 页
buddy_alloc_pages: 偏移 16
buddy_alloc_pages: 分配完成，剩余空闲 32696
8页分配成功: 0xffffffffc020f598
buddy_free_pages: 释放 8 页，实际释放 8 页，偏移 16
buddy_free_pages: 找到节点 32719，对应偏移 16
buddy_free_pages: 更新节点 16359，大小 8
buddy_free_pages: 释放完成，剩余空闲 32704
多页分配测试通过
=== 伙伴系统基本检查完成 ===
check_alloc_page() succeeded!
```
因为上述测试多页设计的页数较少，我们又添加了部分代码进行了大块内存分配的测试，测试成功：
```c
测试4: 分配大块...
buddy_alloc_pages: 请求 128 页，实际分配 128 页
buddy_alloc_pages: 在节点 256 分配 128 页
buddy_alloc_pages: 偏移 128
buddy_alloc_pages: 分配完成，剩余空闲 32576
buddy_free_pages: 释放 128 页，实际释放 128 页，偏移 128
buddy_free_pages: 找到节点 32831，对应偏移 128
buddy_free_pages: 更新节点 16415，大小 128
buddy_free_pages: 释放完成，剩余空闲 32704
大块分配测试通过
=== 所有测试通过! ===
```
--------------------------------



# 扩展练习Challenge：任意大小的内存单元slub分配算法（需要编程）


## 架构设计

###  两层架构
```
┌─────────────────────────────────────┐
│   用户层 (kmalloc/kfree接口)         │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│   第二层：SLUB对象分配器              │
│   - 按大小分类管理                    │
│   - freelist快速分配                 │
│   - partial/full链表管理             │
└──────────────┬──────────────────────┘
               │ alloc_page/free_page
┌──────────────▼──────────────────────┐
│   第一层：PMM页面分配器               │
│   - 管理4KB页面                      │
│   - first_fit/best_fit算法          |
└─────────────────────────────────────┘
```

### 数据结构

slub中定义了kmem_cache缓存每个大小类对应一个cache，管理特定大小的对象，且大小不变

```c
struct kmem_cache {
    const char *name;               // 缓存名称
    size_t size;                    // 对象大小（对齐后）
    size_t objsize;                 // 实际对象大小
    unsigned int num;               // 每个slab中的对象数量
    struct kmem_cache_node node;    // slab链表管理
};
```
字段说明：kmem_cache_node（slab链表管理）管理同一大小类的所有slab页。
还有空闲对象的slab，优先从这里分配，已满的slab，不能再分配，仅用于释放时查找

```c
struct kmem_cache_node {
    list_entry_t partial;       // 部分使用的slab链表
    list_entry_t full;          // 完全使用的slab链表
    unsigned long nr_partial;   // partial链表中的slab数量
    unsigned long nr_full;      // full链表中的slab数量
};
```

利用已有的Page结构存储slab元数据，避免额外空间开销。

```c
struct Page {
    int ref;                    // 复用：存储cache指针
    uint64_t flags;             // 添加PG_slab标志
    unsigned int property;      // 复用：存储freelist指针
    list_entry_t page_link;     // 链接到cache的slab链表
};
```

维护一个在每个空闲对象的开头存储指针，形成空闲链表。
```c
struct freelist_node {
    struct freelist_node *next;
};
```


## 核心算法

### 初始化流程

```
slub_init()
├─ 1. 定义大小类数组
│     [8, 16, 32, 64, 128, 256, 512, 1024, 2048]
│
├─ 2. 为每个大小类创建kmem_cache
│     ├─ 计算每个slab可容纳的对象数
│     ├─ 初始化partial/full链表
│     └─ 设置缓存属性
│
└─ 3. 输出初始化信息
```

**关键代码** ：
```c
for (i = 0; i < SLUB_SIZE_COUNT; i++) {
    struct kmem_cache *cache = &kmalloc_caches[i];
    cache->size = kmalloc_sizes[i];
    cache->num = PGSIZE / cache->size;  // 4KB / 对象大小
    list_init(&cache->node.partial);
    list_init(&cache->node.full);
}
```

### 分配算法（kmalloc）

用户层提供的接口kmalloc，用来分配用户所需要的内存

```
kmalloc(size)
├─ 1. 大小检查
│     ├─ size == 0 → 返回NULL
│     └─ size > 2048 → 返回NULL（超出范围）
│
├─ 2. 选择合适的cache
│     向上取整到最近的大小类
│     例如：申请30字节 → 使用32字节cache
│
├─ 3. 尝试从partial链表分配
│     ├─ 如果partial非空
│     │   ├─ 从slab的freelist取出首个对象
│     │   ├─ 更新freelist指针
│     │   ├─ 空闲计数-1
│     │   └─ 如果slab变满 → 移到full链表
│     └─ 返回对象地址
│
├─ 4. 如果partial为空，分配新slab
│     ├─ 调用alloc_page()分配一页
│     ├─ 初始化slab
│     │   ├─ 设置PG_slab标志
│     │   ├─ 存储cache指针
│     │   ├─ 建立freelist
│     │   └─ 设置空闲计数
│     ├─ 从新slab分配一个对象
│     └─ 将slab加入partial链表
│
└─ 5. 返回对象地址
```



### 释放算法（kfree）

用户层提供的接口kfree，用来分配用户所需要的内存
```
kfree(objp)
├─ 1. 空指针检查
│     objp == NULL → 直接返回
│
├─ 2. 地址转换和页面定位
│     ├─ 虚拟地址 → 物理地址
│     └─ 物理地址 → Page结构 (pa2page)
│
├─ 3. 验证slab页
│     检查PG_slab标志
│
├─ 4. 获取cache信息
│     从Page->ref获取kmem_cache指针
│
├─ 5. 将对象归还到freelist
│     ├─ 在对象头部写入当前freelist指针
│     ├─ 更新slab的freelist指向该对象
│     └─ 空闲计数+1
│
├─ 6. 更新slab状态
│     ├─ 如果从full变为partial
│     │   └─ 移动链表：full → partial
│     └─ 如果slab完全空闲
│         └─ 释放回页分配器（保留至少1个partial slab）
│
└─ 7. 完成释放
```

### slab初始化

```c
void init_slab(struct Page *page, struct kmem_cache *cache) {
    SetPageSlab(page);
    set_page_cache(page, cache);
    
    uintptr_t addr = page2pa(page) + PHYSICAL_MEMORY_OFFSET;
    size_t num = PGSIZE / cache->size;
    
    // 建立freelist链表
    struct freelist_node *current = (struct freelist_node *)addr;
    for (i = 0; i < num - 1; i++) {
        current->next = (struct freelist_node *)(addr + (i+1) * cache->size);
        current = current->next;
    }
    current->next = NULL;
    
    set_page_freelist(page, (struct freelist_node *)addr);
    page->property = num;
}
```

使用页的虚拟地址（物理地址 + PHYSICAL_MEMORY_OFFSET）,freelist指针指向对象在内存中的实际位置,每个对象的前8字节用于存储next指针

## 测试方案：

### 测试用例设计

#### 测试1：基本分配与释放

1. 分配32字节对象
2. 写入数据0x12345678
3. 验证数据正确性
4. 释放对象
5. 再次分配32字节
6. 检查空间是否可复用（分配的地址是否相同）
```c
    // 测试1：基本分配与释放
    cprintf("\n[测试1] 基本分配与释放\n");
    cprintf("准备分配32字节...\n");
    {
        void *p1 = kmalloc(32);
        assert(p1 != NULL);
        cprintf("  分配32字节: %p\n", p1);
        
        // 写入数据验证可用性
        *(int *)p1 = 0x12345678;
        assert(*(int *)p1 == 0x12345678);
        cprintf("  数据写入验证: OK\n");
        
        kfree(p1);
        cprintf("  释放对象: OK\n");
        
        // 再次分配，应该复用刚释放的对象
        void *p2 = kmalloc(32);
        assert(p2 != NULL);
        cprintf("  再次分配32字节: %p ", p2);
        if (p2 == p1) {
            cprintf("(复用成功)\n");
        } else {
            cprintf("(新对象)\n");
        }
        kfree(p2);
    }
    cprintf("[测试1] 通过!\n");
```



#### 测试2：多种大小对象分配

1. 同时分配5个不同大小的对象（8, 64, 128, 256, 512字节，涵盖实际中常用的大小）
2. 每个对象写入不同的数据
3. 验证数据独立性（互不影响）
4. 按顺序释放所有对象

```c
    // 测试2：多种大小对象分配
    cprintf("\n[测试2] 多种大小对象分配\n");
    {
        void *objs[5];
        size_t sizes[] = {8, 64, 128, 256, 512};
        int i;
        
        // 分配不同大小的对象
        for (i = 0; i < 5; i++) {
            objs[i] = kmalloc(sizes[i]);
            assert(objs[i] != NULL);
            cprintf("  分配%d字节: %p\n", sizes[i], objs[i]);
            
            // 写入不同的数据
            *(int *)objs[i] = i * 0x1000;
        }
        
        // 验证数据独立性
        for (i = 0; i < 5; i++) {
            assert(*(int *)objs[i] == i * 0x1000);
        }
        cprintf("  数据独立性验证: OK\n");
        
        // 释放所有对象
        for (i = 0; i < 5; i++) {
            kfree(objs[i]);
        }
        cprintf("  释放所有对象: OK\n");
    }
    cprintf("[测试2] 通过!\n");
```

#### 测试3：连续分配测试


1. 连续分配20个32字节对象（超过单个slab容量）
2. 触发新slab分配，记录slab数量
3. 每个对象写入唯一标识
4. 验证所有数据正确
5. 释放一半对象
6. 再次分配相同数量对象
7. 释放所有对象

```c
   // 测试3：连续分配测试（触发slab扩展）
    cprintf("\n[测试3] 连续分配测试\n");
    {
        #define TEST_ALLOC_COUNT 20
        void *objs[TEST_ALLOC_COUNT];
        int i;
        
        // 连续分配20个32字节对象（可能触发新slab分配）
        cprintf("  连续分配%d个32字节对象...\n", TEST_ALLOC_COUNT);
        for (i = 0; i < TEST_ALLOC_COUNT; i++) {
            objs[i] = kmalloc(32);
            assert(objs[i] != NULL);
            *(int *)objs[i] = i;
        }
        cprintf("  分配完成\n");
        
        // 验证数据
        for (i = 0; i < TEST_ALLOC_COUNT; i++) {
            assert(*(int *)objs[i] == i);
        }
        cprintf("  数据完整性验证: OK\n");
        
        // 释放一半对象
        for (i = 0; i < TEST_ALLOC_COUNT / 2; i++) {
            kfree(objs[i]);
        }
        cprintf("  释放一半对象: OK\n");
        
        // 再次分配，应该从partial链表复用
        for (i = 0; i < TEST_ALLOC_COUNT / 2; i++) {
            objs[i] = kmalloc(32);
            assert(objs[i] != NULL);
            *(int *)objs[i] = i + 1000;
        }
        cprintf("  重新分配: OK\n");
        
        // 释放所有对象
        for (i = 0; i < TEST_ALLOC_COUNT; i++) {
            kfree(objs[i]);
        }
        cprintf("  释放所有对象: OK\n");
    }
    cprintf("[测试3] 通过!\n");
```

利用assert断言机制降低在程序中进行频繁判断的成本，或者说让代码看起来更精简


### 6.2 测试输出示例

```c
[测试1] 基本分配与释放
准备分配32字节...
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配32字节: 0xffffffffc0347018
  数据写入验证: OK
  释放对象: OK
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
  再次分配32字节: 0xffffffffc0347018 (复用成功)
[测试1] 通过!
```
测试1中我们分配了一个32位空间，输出如上
```c

[测试2] 多种大小对象分配
kmalloc: size=8, cache_index=0, cache_size=8
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配8字节: 0xffffffffc0348018
kmalloc: size=64, cache_index=3, cache_size=64
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配64字节: 0xffffffffc0349018
kmalloc: size=128, cache_index=4, cache_size=128
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配128字节: 0xffffffffc034a018
kmalloc: size=256, cache_index=5, cache_size=256
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配256字节: 0xffffffffc034b018
kmalloc: size=512, cache_index=6, cache_size=512
kmalloc: allocating new slab...
kmalloc: new slab allocated
kmalloc: object allocated from new slab
  分配512字节: 0xffffffffc034c018
  数据独立性验证: OK
  释放所有对象: OK
[测试2] 通过!


```
测试2中我们分配了多种大小不同的空间，并验证了彼此数据的独立性
```c

[测试3] 连续分配测试
  连续分配20个32字节对象...
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
  分配完成
  数据完整性验证: OK
  释放一半对象: OK
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
kmalloc: size=32, cache_index=2, cache_size=32
kmalloc: using existing partial slab
  重新分配: OK
  释放所有对象: OK
[测试3]通过！
```
测试3我们验证了链表管理，单个slab容量为4096，如果我们要测试slab扩展，我们需要分配更多的连续空间
我们分配了130个32字节的空间用来测试，由于输出的代码巨长，所以不在这里粘贴，但是我们已经对slab扩展进行了测试

--------------------------------




# 扩展练习Challenge：硬件的可用物理内存范围的获取方法（思考题）
当OS无法提前获得硬件信息时，它必须采用一种“探索式”的方法来发现系统资源。

以下是几种在“盲测”或信息有限的情况下，操作系统获取可用物理内存范围的关键技术和方法：

**核心原则：循序渐进的探索**
操作系统通常不会只依赖一种方法，而是组合多种方法，由简到繁，由已知到未知，逐步构建出完整的内存地图。

### **方法一：利用固件（Firmware）提供的服务**
通常固件知道关于硬件的信息，OS可以通过调用固件提供的接口来查询。

1. **BIOS (x86架构)：**

INT 0x15, AX=0xE820：这是最重要和最强大的BIOS内存探测功能。它会返回一个描述内存映射的地址范围描述符结构数组，其中详细列出了：

- **可用（Available）** RAM。

- **保留（Reserved）** 区域（被BIOS、设备等使用）。

- **ACPI表** 所在区域。

- **不可用（Bad Memory）** 的损坏内存。

操作系统在实模式或保护模式的虚拟8086模式下调用此中断，遍历所有条目，即可构建出完整的内存地图。

2. **UEFI (现代x86/ARM架构)：**

**GetMemoryMap() Boot Service：** UEFI提供了一个更现代、更结构化的引导服务。OS引导加载程序（如GRUB）可以在退出Boot Services之前调用这个函数，获取一个非常精确和详细的内存映射。这是现代UEFI系统的标准做法。

**但是即使固件提供了信息，OS内核也必须在接管硬件后对其进行验证，因为固件有时会出错。**

### **方法二：物理内存探测**
当固件接口不可用、不可信或不存在（如在某些嵌入式系统或虚拟化环境中）时，OS必须亲自进行“触摸”式探测。这是一种高风险但有效的方法。

**基本思想：尝试读写某些物理地址，观察系统的反应。**

1. **写-读验证：**

选择一个候选的内存地址；
向该地址写入一个已知的模式（例如，0x55AA55AA）；
从该地址读回数据；
如果读回的数据与写入的数据一致，则该地址很可能存在可用的RAM。

**风险**：写入某些设备内存（Memory-Mapped I/O, MMIO）可能导致未定义行为（系统崩溃、设备异常）。

2. **如何安全地进行？**

**从已知的安全区域开始：** 假设低端1MB内存的某些部分是已知的（例如，640KB的基本内存）。从1MB边界（0x100000）之后开始探测。

**跳过已知的保留区域：** 跳过BIOS ROM、APIC、IOAPIC等固定地址区域。

**递增式探测：** 以较大的步长（如1MB或4KB）递增地址进行探测。

**使用“墓碑”技术：**
在探测地址A之前，先读取并保存A处的原始值（墓碑），然后进行写-读验证；
无论验证成功与否，最后都必须将原始值写回。这对于共享内存区域或某些设备的“只写”寄存器至关重要。

**观察异常：** 如果探测触发了处理器异常（如Page Fault, Machine Check Exception），则说明该地址无效或受保护。异常处理程序可以记录这个地址为非法，然后恢复执行。

3. **在x86架构上的一个经典技巧：**

启用处理器的分页机制，但将整个地址空间映射为“不存在”或只读。

当尝试访问一个不存在的物理地址时，会触发Page Fault。

在Page Fault处理程序中，检查出错的地址。

- 如果该地址是有效的RAM，则建立页表映射，使其可访问。

- 如果该地址无效，则记录该区域为不可用，并跳过它。

### **方法三：解析高级配置信息**
现代计算平台提供了更高级的配置表，这些表由固件在启动时构建。

1. **ACPI (高级配置与电源接口)：**

系统固件会在内存中放置RSDP指针；

OS通过RSDP找到RSDT或XSDT，进而找到MADT（用于CPU）、SRAT（NUMA内存）等表；

最重要的是 SPCR (Serial Port Console Redirection) 和 SLIC 等，但最关键的是，ACPI定义了系统硬件的静态配置，其中隐含着内存映射信息。NFIT (NVDIMM Firmware Interface Table) 则专门用于描述持久内存的范围。

2. **设备树 (Device Tree - DTB)：**

在ARM、RISC-V 和 PowerPC 等嵌入式或开放平台上非常普遍；

引导加载程序（如U-Boot）会将一个描述硬件布局的设备树二进制blob (DTB) 的地址传递给内核；

这个DTB文件中明确包含了memory节点，直接定义了可用物理内存的起始地址和大小；

**在这种情况下，OS不需要探测，直接从DTB解析即可。**

### 实践中的组合策略
一个成熟的操作系统（如Linux）会按以下顺序操作：

1. **初期依赖：** 在引导初期，完全依赖引导加载程序（如GRUB）传递过来的信息，这些信息通常来自BIOS/E820或UEFI GetMemoryMap()。

2. **内核重探测：** 内核启动后，出于安全性和精确性的考虑，会重新调用BIOS的E820中断或UEFI服务，获取第一手资料。

3. **验证与补充：** 使用轻量级的探测或解析ACPI/Device Tree来验证和补充内存映射，特别是处理一些特殊区域（如ACPI NVS, Persistent Memory）。

4. **构建内存映射：** 最终，内核将所有来源的信息整合，生成一个权威的 mem_map 或 memblock 数据结构，供内核的内存管理子系统使用。

**结论：** 没有一个万全之策。在实际操作系统中，利用固件服务是首选和最安全的方法。只有当此路不通时，才会退而求其次，采用谨慎的、带有异常处理的物理内存探测方法，并辅以对ACPI、设备树等高级配置信息的解析，从而安全、准确地绘制出整个系统的物理内存地图。







