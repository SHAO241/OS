# Lab8 页错误处理与用户内存访问安全 - 修改笔记

## 一、核心问题

在 Lab8 中，用户程序执行时会触发页错误（Page Fault），需要在内核中正确处理：
1. **有效的页错误**：如访问未分配的 BSS 段，应分配物理页并映射
2. **无效的页错误**：如访问内核地址或不在 VMA 范围的地址，应杀死进程
3. **系统调用安全**：内核不能直接访问用户传入的指针，需要先验证

## 二、修改文件清单

### 1. kern/trap/trap.c - 页错误处理入口

**问题**：原始代码中页错误处理只是打印错误信息并递增 epc，没有真正处理。

**修改内容**：

```c
// 添加页错误信息打印函数
static void print_pgfault(struct trapframe *tf) {
    /* 
     * 打印页错误的详细信息：
     * - scause: 页错误类型（取指令/读数据/写数据）
     * - sepc: 触发页错误的指令地址
     * - stval: 导致页错误的虚拟地址
     */
    cprintf("%s page fault\n", 
            (tf->cause == CAUSE_LOAD_PAGE_FAULT) ? "Load/AMO" : 
            (tf->cause == CAUSE_STORE_PAGE_FAULT) ? "Store/AMO" : "Instruction");
}

// 添加页错误处理函数
static int pgfault_handler(struct trapframe *tf) {
    /*
     * 页错误处理流程：
     * 1. 获取当前进程的内存管理结构 mm
     * 2. 检查 mm 是否为空（内核线程没有 mm）
     * 3. 调用 do_pgfault 尝试处理页错误
     * 4. 返回处理结果（0=成功，非0=失败）
     */
    extern struct mm_struct *check_mm_struct;
    
    // 如果是用户进程，使用进程的 mm；否则使用全局的 check_mm_struct
    struct mm_struct *mm;
    if (check_mm_struct != NULL) {
        // 用于测试的特殊情况
        mm = check_mm_struct;
    } else {
        // 正常情况：使用当前进程的 mm
        mm = current->mm;
    }
    
    // 调用 vmm 层的页错误处理函数
    return do_pgfault(mm, tf->cause, tf->tval);
}

// 在 exception_handler 中修改三个页错误处理分支
void exception_handler(struct trapframe *tf) {
    int ret;
    switch (tf->cause) {
        // ... 其他异常处理 ...
        
        case CAUSE_LOAD_PAGE_FAULT:      // 读取数据页错误
        case CAUSE_STORE_PAGE_FAULT:     // 写入数据页错误
        case CAUSE_FETCH_PAGE_FAULT:     // 取指令页错误
            /*
             * 处理流程：
             * 1. 打印页错误信息（便于调试）
             * 2. 调用 pgfault_handler 处理
             * 3. 如果处理失败，杀死进程
             */
            print_pgfault(tf);
            if ((ret = pgfault_handler(tf)) != 0) {
                // 页错误无法处理，打印 trapframe 并终止进程
                print_trapframe(tf);
                if (current == NULL) {
                    panic("handle pgfault failed. ret=%d\n", ret);
                } else {
                    // 如果是用户进程，杀死该进程
                    if (trap_in_kernel(tf)) {
                        panic("handle pgfault failed in kernel mode. ret=%d\n", ret);
                    }
                    cprintf("killed by kernel.\n");
                    do_exit(-E_KILLED);
                }
            }
            break;
            
        // ... 其他异常处理 ...
    }
}
```

**关键点**：
- `pgfault_handler` 根据是否有 mm 结构决定是否处理
- 内核态页错误会导致 panic（不应该发生）
- 用户态无法处理的页错误会杀死进程

---

### 2. kern/mm/vmm.c - 页错误处理核心实现

**问题**：缺少 `do_pgfault` 函数实现，以及安全的用户内存访问函数。

**修改内容**：

```c
// 添加全局变量定义（用于测试）
struct mm_struct *check_mm_struct = NULL;

/*
 * do_pgfault - 页错误处理的核心函数
 * @mm: 内存管理结构
 * @error_code: 错误类型（读/写/执行）
 * @addr: 触发页错误的虚拟地址
 * 
 * 返回值：0=成功处理，非0=处理失败
 */
int do_pgfault(struct mm_struct *mm, uint32_t error_code, uintptr_t addr) {
    int ret = -E_INVAL;
    
    // 第一步：查找包含该地址的 VMA（虚拟内存区域）
    struct vma_struct *vma = find_vma(mm, addr);

    // 第二步：验证地址是否合法
    if (vma == NULL || vma->vm_start > addr) {
        // 地址不在任何 VMA 范围内，这是非法访问
        cprintf("not valid addr %x, and can not find it in vma\n", addr);
        goto failed;
    }

    // 第三步：设置页表项权限
    /* 
     * RISC-V 页表权限位：
     * - PTE_V: 页表项有效
     * - PTE_R: 可读
     * - PTE_W: 可写
     * - PTE_X: 可执行
     * - PTE_U: 用户态可访问
     */
    uint32_t perm = PTE_U | PTE_V;  // 基础权限：用户态+有效
    if (vma->vm_flags & VM_WRITE) {
        perm |= (PTE_R | PTE_W);    // 可写区域同时需要可读
    }
    if (vma->vm_flags & VM_READ) {
        perm |= PTE_R;              // 可读权限
    }
    if (vma->vm_flags & VM_EXEC) {
        perm |= PTE_X;              // 可执行权限
    }
    
    // 第四步：页对齐地址
    addr = ROUNDDOWN(addr, PGSIZE);  // 向下对齐到页边界

    ret = -E_NO_MEM;

    // 第五步：获取或创建页表项
    pte_t *ptep = get_pte(mm->pgdir, addr, 1);  // 1 表示如果不存在则创建
    
    if (*ptep == 0) {
        // 情况1：页表项不存在，需要分配新的物理页
        if (pgdir_alloc_page(mm->pgdir, addr, perm) == NULL) {
            cprintf("pgdir_alloc_page in do_pgfault failed\n");
            goto failed;
        }
    } else {
        // 情况2：页表项已存在
        /*
         * 这种情况可能是：
         * - 权限不足（如写时复制 COW）
         * - 页面被换出到磁盘（swap）
         * 目前简单处理：如果页面存在就认为成功
         */
        struct Page *page = pte2page(*ptep);
        if (page != NULL) {
            ret = 0;  // 页面已存在，成功
        } else {
            cprintf("pte is not zero but page is NULL\n");
            goto failed;
        }
    }

    ret = 0;  // 成功处理
failed:
    return ret;
}

/*
 * copy_to_user - 安全地将数据从内核复制到用户空间
 * @mm: 用户进程的内存管理结构
 * @dst: 用户空间目标地址
 * @src: 内核空间源地址
 * @len: 复制长度
 * 
 * 返回值：1=成功，0=失败
 * 
 * 安全检查：
 * 1. 验证 dst 在用户空间范围内
 * 2. 验证 dst 在进程的 VMA 范围内
 * 3. 验证 dst 有写权限
 */
bool copy_to_user(struct mm_struct *mm, void *dst, const void *src, size_t len)
{
    // 使用 user_mem_check 验证目标地址的合法性
    if (!user_mem_check(mm, (uintptr_t)dst, len, 1))  // 1 表示检查写权限
    {
        return 0;  // 验证失败
    }
    // 验证通过，执行复制
    memcpy(dst, src, len);
    return 1;
}

/*
 * copy_from_user - 安全地将数据从用户空间复制到内核
 * @mm: 用户进程的内存管理结构
 * @dst: 内核空间目标地址
 * @src: 用户空间源地址
 * @len: 复制长度
 * @writable: 是否需要写权限（通常为 false）
 * 
 * 返回值：1=成功，0=失败
 */
bool copy_from_user(struct mm_struct *mm, void *dst, const void *src, size_t len, bool writable)
{
    // 验证源地址的合法性
    if (!user_mem_check(mm, (uintptr_t)src, len, writable))
    {
        return 0;
    }
    memcpy(dst, src, len);
    return 1;
}
```

**关键点**：
- `do_pgfault` 通过 VMA 验证地址合法性
- 根据 VMA 的权限标志设置页表权限
- `copy_to_user/copy_from_user` 必须先调用 `user_mem_check` 验证

---

### 3. kern/mm/vmm.h - 函数声明

**修改内容**：

```c
// 在文件中添加 do_pgfault 的函数声明
int do_pgfault(struct mm_struct *mm, uint32_t error_code, uintptr_t addr);
```

---

### 4. kern/process/proc.c - 系统调用中安全访问用户指针

**问题**：`do_wait` 中直接写入用户传入的指针 `code_store`，不安全。

**修改内容**：

```c
int do_wait(int pid, int *code_store)
{
    struct mm_struct *mm = current->mm;
    
    // 第一步：验证用户传入的指针
    if (code_store != NULL)
    {
        /*
         * user_mem_check 验证内容：
         * 1. 地址在用户空间范围内（USERBASE ~ USERTOP）
         * 2. 地址在进程的某个 VMA 内
         * 3. VMA 有写权限（因为 write=1）
         */
        if (!user_mem_check(mm, (uintptr_t)code_store, sizeof(int), 1))
        {
            return -E_INVAL;  // 地址非法，返回错误
        }
    }

    struct proc_struct *proc;
    bool intr_flag, haskid;
    
repeat:
    // ... 查找子进程的代码（省略）...

found:
    if (proc == idleproc || proc == initproc)
    {
        panic("wait idleproc or initproc.\n");
    }
    
    // 第二步：使用 copy_to_user 安全地写入退出码
    if (code_store != NULL)
    {
        /*
         * copy_to_user 会再次验证地址并执行复制
         * 这是双重保护，确保即使地址在验证后被修改也能捕获
         */
        if (!copy_to_user(mm, code_store, &(proc->exit_code), sizeof(int)))
        {
            return -E_INVAL;
        }
    }
    
    // 第三步：清理子进程资源
    local_intr_save(intr_flag);
    {
        unhash_proc(proc);
        remove_links(proc);
    }
    local_intr_restore(intr_flag);
    put_kstack(proc);
    kfree(proc);
    return 0;
}
```

**关键改进**：
- 在函数开始就验证 `code_store` 的合法性
- 使用 `copy_to_user` 而不是直接 `*code_store = ...`
- 如果验证失败立即返回 -E_INVAL，防止内核崩溃

---

### 5. user/libs/ulib.c - 修复 waitpid 实现

**问题**：原始实现在系统调用返回后尝试写入用户指针，如果指针无效会在用户态触发页错误。

**原始代码（有问题）**：
```c
int waitpid(int pid, int *store) {
    int64_t exit_code_store;
    int ret;
    
    if (store == NULL) {
        return sys_wait(pid, NULL);
    }
    
    ret = sys_wait(pid, &exit_code_store);  // 使用栈上的变量
    
    // 问题：如果 store 是无效地址（如 0xC0000000），
    // 这里会在用户态触发页错误，导致进程被杀死
    if (ret == 0 && store != NULL) {
        *store = (int)exit_code_store;  // <-- 危险：可能访问非法地址
    }
    
    return ret;
}
```

**修复后的代码**：
```c
/*
 * waitpid - 等待子进程结束
 * @pid: 子进程 PID（0 表示任意子进程）
 * @store: 用于存储子进程退出码的指针
 * 
 * 返回值：0=成功，负数=错误码
 * 
 * 设计原则：
 * 让内核验证和处理用户指针，而不是在用户态处理
 */
int waitpid(int pid, int *store) {
    // 直接传递用户指针给系统调用
    // 类型转换：int* -> int64_t*（内核期望的类型）
    return sys_wait(pid, (int64_t *)store);
}
```

**为什么这样修复**：
1. **内核验证更安全**：内核中的 `user_mem_check` 可以完整验证地址
2. **避免用户态崩溃**：如果地址无效，系统调用返回错误而不是触发页错误
3. **简化代码**：不需要中间变量，直接传递指针

---

## 三、测试用例分析

### 1. badarg 测试

**测试代码**：
```c
int main(void) {
    int pid, exit_code;
    if ((pid = fork()) == 0) {
        // 子进程
        for (i = 0; i < 10; i++) yield();
        exit(0xbeaf);
    }
    
    // 父进程测试非法参数
    assert(waitpid(-1, NULL) != 0);              // 测试1：无效PID
    assert(waitpid(pid, (void *)0xC0000000) != 0); // 测试2：无效地址（内核地址）
    assert(waitpid(pid, &exit_code) == 0);       // 测试3：正常调用
    
    cprintf("badarg pass.\n");
    return 0;
}
```

**执行流程**：
1. 测试1：`waitpid(-1, NULL)` → 返回 -E_BAD_PROC（找不到 PID=-1 的子进程）
2. 测试2：`waitpid(pid, 0xC0000000)` → `user_mem_check` 检测到地址在内核空间 → 返回 -E_INVAL
3. 测试3：`waitpid(pid, &exit_code)` → 正常等待并返回退出码 0xbeaf

**关键**：测试2 不应该触发页错误，而是系统调用返回错误码。

### 2. testbss 测试

**测试目的**：验证 BSS 段的延迟分配（lazy allocation）

**执行流程**：
1. 访问 BSS 段的数组 → 触发页错误 → `do_pgfault` 分配物理页 → 成功
2. 故意写入超出 BSS 范围的地址 → 触发页错误 → `do_pgfault` 发现不在 VMA 内 → 失败 → 进程被杀死

**预期结果**：
```
Making sure bss works right...
Yes, good.  Now doing a wild write off the end...
testbss may pass.
not valid addr c02000, and can not find it in vma
killed by kernel.
error: -9 - process is killed
```

这是**正常行为**，说明页错误处理正确区分了合法和非法访问。

---

## 四、核心知识点总结

### 1. 页错误处理流程

```
用户程序访问内存
    ↓
触发页错误异常
    ↓
trap.c: exception_handler
    ↓
trap.c: pgfault_handler
    ↓
vmm.c: do_pgfault
    ├─ 查找 VMA
    ├─ 检查权限
    ├─ 分配物理页
    └─ 建立映射
    ↓
返回用户态继续执行
```

### 2. 用户内存访问安全原则

**三不原则**：
1. **不直接解引用用户指针**：可能指向非法地址
2. **不假设用户数据合法**：必须验证所有用户输入
3. **不在用户态处理非法地址**：应该在内核验证并返回错误

**正确做法**：
```c
// ❌ 错误：直接访问用户指针
*user_ptr = kernel_value;

// ✅ 正确：先验证再访问
if (user_mem_check(mm, user_ptr, size, 1)) {
    copy_to_user(mm, user_ptr, &kernel_value, size);
}
```

### 3. VMA（虚拟内存区域）的作用

每个进程的地址空间由多个 VMA 组成：
- **代码段 VMA**：[0x200000, ...），权限：VM_READ | VM_EXEC
- **数据段 VMA**：[..., ...]，权限：VM_READ | VM_WRITE
- **BSS 段 VMA**：[..., ...]，权限：VM_READ | VM_WRITE
- **栈 VMA**：[USTACKTOP-USTACKSIZE, USTACKTOP)，权限：VM_READ | VM_WRITE | VM_STACK

页错误处理时，通过 VMA 判断：
- 地址是否在合法范围（vma->vm_start ≤ addr < vma->vm_end）
- 访问类型是否符合权限（读/写/执行）

### 4. RISC-V 页表权限位

```c
#define PTE_V 0x001  // Valid：页表项有效
#define PTE_R 0x002  // Read：可读
#define PTE_W 0x004  // Write：可写
#define PTE_X 0x008  // Execute：可执行
#define PTE_U 0x010  // User：用户态可访问
```

**重要规则**：
- 可写页必须同时设置 PTE_R（RISC-V 要求）
- 用户页必须设置 PTE_U
- 内核页不设置 PTE_U

---

# 指导书

## 文件系统概述

处理具体设备，具体协议并向上提供简单接口的软件，我们叫做设备驱动(device driver)，简称驱动。

**虚拟文件系统（virtual filesystem, VFS）**, 作为操作系统和更具体的文件系统之间的接口


所谓“**具体文件系统**”，指的是更**接近具体设备和文件系统**的**内部实现**，而“**虚拟文件系统**”更接近**用户使用**的接口。


在Linux系统中，如`/floppy`是一块`MS-DOS`文件系统的软盘的挂载点，`/tmp/test`是`Ext2`文件系统的一个目录，我们执行`cp /floppy/TEST /tmp/test`, 进行目录的拷贝，相当于执行下面这段代码：

```c
inf = open("/floppy/TEST", O_RDONLY, 0); 
outf = open("/tmp/test", O_WRONLY|O_CREAT|O_TRUNC, 0600);
do {
    i = read(inf, buf, 4096);
    write(outf, buf, i);
} while (i);
close(outf);
close(inf);
```
对于**不同文件系统**的目录，我们可以使用**相同**的open，read，write，close接口，好像它们在同一个文件系统里一样。这是**虚拟文件系统**的功能。

### UNIX文件系统

`UNIX` 文件中的内容可理解为是一段有序的字节 

占用磁盘上可能**连续或不连续**的一些空间（实际占用的空间可能比你存储的数据要多）

每个文件都有一个**方便应用程序识别**的**文件名**（也可以称作路径`path`），另外有一个**文件系统内部使用**的**编号**（用户程序不知道这个底层编号）

**目录(directory)** 是特殊的文件，一个目录里包含若干其他文件或目录。

在 `UNIX `中，文件系统可以被安装在一个**特定的文件路径位置**，这个位置就是**挂载点**

所有的已安装**文件系统**都作为**根文件系统树中的叶子**出现在系统中。

比如当你把U盘插进来，系统检测到U盘之后，会给**U盘的文件系统**一个**挂载点**，这个挂载点是原先的 **`UNIX`操作系统的叶子**，但也可以认为是**U盘文件系统的根节点**。

`UNIX`的文件系统中，有一个**通用文件模型（Common File Model）**，**所有具体**的文件系统(不管是Ext4，ZFS还是FAT)，都需要**提供**通用文件模型所**约定的行为**。


**通用文件模型定义了一些对象:**

- **超级块(superblock)**：存储整个文件系统的相关信息。对于磁盘上的文件系统，对应磁盘里的**文件系统控制块(filesystem control block)**

- **索引节点(inode)**：存储关于**某个文件**的**元数据信息**（如访问控制权限、大小、拥有者、创建时间、数据内容等等），通常对应磁盘上的**文件控制块(file control block)**. 每个索引节点有一个**编号**，唯一确定文件系统里的一个文件。

- **文件(file)**: 这里定义的`file object`不是指磁盘上的一个”文件“， 而是指一个**进程**和**它打开的一个文件之间**的**关系**，这个对象存储在**内核态的内存**中，仅当某个进程打开某个文件的时候才存在。

- **目录项（dentry）：** 维护从”**目录里的某一项**“到”**对应的文件**“的**链接/指针**。一个目录也是一个文件，包含若干个子目录和其他文件。从**某个子目录、文件的名称**，对应到**具体的文件/子目录的地址(或者索引节点inode)的链接**，通过目录项(dentry)来描述。


需要通过一个**具体文件系统**的架构，把**上述信息**映射并**储存到磁盘介质**上，从而在具体文件系统的磁盘布局（即数据在磁盘上的物理组织）上体现出上述抽象概念。

比如**文件元数据信息**存储在**磁盘块中的索引节点**上。当文件被载入**内存**时，内核需要使用**磁盘块中的索引点**来**构造内存中的索引节点**。


又比如`dentry`对象在磁盘上不存在，但是当一个目录包含的某一项（可能是子目录或文件）的信息被载入到内存时，内核会构建对应的`dentry`对象，如`/tmp/test`这个路径，在解析的过程中，内核为根目录`/`创建一个`dentry`对象，为根目录的成员`tmp`构建一个`dentry`对象，为`/tmp`目录的成员`test`也构建一个`dentry`对象。

### ucore 文件系统总体介绍

`lab8`的`Makefile`和之前不同，分三段构建内核镜像:
1. `sfs.img`: 一块符合`SFS`文件系统的硬盘，里面存储编译好的用户程序
2. `swap.img`: 一段初始化为`0`的硬盘交换区
3. `kernel objects`: `ucore`内核代码的目标文件


这三部分共同组成`ucore.img`, 加载到`QEMU`里运行。`ucore`代码中，我们通过链接时添加的首尾符号，把`swap.img`和`sfs.img`两段“硬盘”（实际上对应两段内存空间）找出来，然后作为“硬盘”进行管理。


注意，我们要在`ucore`内核开始执行之前，**构造好“一块符合`SFS`文件系统的硬盘”**，这就得另外写个程序做这个事情。这个程序就是`tools/mksfs.c`。

**`ucore` 的文件系统架构主要由四部分组成：**

- **通用文件系统访问接口层：** 该层提供了一个从**用户空间**到**文件系统**的标准访问接口。这一层访问接口让**应用程序**能够通过一个简单的接口**获得 ucore 内核**的**文件系统服务**。
- **文件系统抽象层：** **向上**提供一个一致的**接口** **给内核**其他部分（文件系统相关的系统调用实现模块和其他内核功能模块）访问，**向下**提供一个**同样的抽象函数指针列表**和**数据结构** **屏蔽**不同文件系统的**实现细节**。
- **Simple FS 文件系统层**：一个基于**索引方式**的简单文件系统**实例**。**向上**通过各种**具体函数实现**以对应文件系统抽象层提出的**抽象函数**，**向下**访问**外设接口**。
- **外设接口层：** **向上**提供 `device` **访问接口** **屏蔽不同硬件细节**。**向下**实现访问**各种具体设备驱动的接口**，比如 disk 设备接口 / 串口设备接口 / 键盘设备接口等。

**文件系统的访问处理过程**:

假如应用程序操作文件（打开/创建/删除/读写）

1. 首先需要通过文件系统的**通用文件系统访问接口层**给**用户空间**提供的访问接口**进入**文件系统内部           

2. 接着由**文件系统抽象层**把访问请求**转发**给某一**具体文件系统**    

3. **具体文件系统**（**Simple FS 文件系统层**）把应用程序的**访问请求** **转化**为对磁盘上的 block 的**处理请求**
4. **外设接口层**交给**磁盘驱动例程**来**完成具体的磁盘操作**。

```c
(1)
write::usr/libs/file.c
sys_write::usr/libs/syscall.c
syscall::usr/libs/syscall.c
sys_write::/kern/syscall/syscall.c

(2)
sysfile_write::/kern/fs/sysfile.c
file_write::/kern/fs/file.c
vop_write::/kern/fs/vfs/inode.h


(3)
sfs_write::/kern/fs/sfs/sfs_inode.c
sfs_wbuf::/kern/fs/sfs/sfs_io.c

(4)
dop_io::/kern/fs/devs/dev.h
diskO__io::/kern/fs/devs/dev_diskO.c
ide_write_secs::/kern/driver/ide.c

```

### ucore 文件系统总体结构

从 `ucore `操作系统不同的角度来看，`ucore` 中的文件系统架构包含四类主要的数据结构, 它们分别是：


- **超级块（SuperBlock）**，它主要从**文件系统的全局角度**描述特定文件系统的**全局信息**。它的作用范围是**整个 OS 空间**。
- **索引节点（inode）**：它主要**从文件系统的单个文件的角度**,它描述了**文件的各种属性和数据所在位置**。它的作用范围是**整个 OS 空间**。
- **目录项（dentry）**：它主要从**文件系统的文件路径的角度**描述了文件路径中的一个特定的目录项（注：一系列目录项形成目录/文件路径）。它的作用范围**是整个 OS 空间**。对于 SFS 而言，**inode**(具体为 struct sfs_disk_inode)对应于**物理磁盘上的具体对象**，**dentry**（具体为 struct sfs_disk_entry）是一个**内存实体**，其中的 ino 成员指向对应的 inode number，另外一个成员是 file name(文件名).
- **文件（file）**，它主要从**进程的角度**描述了一个进程在访问文件时需要了解的文件标识，文件读写的位置，文件引用情况等信息。它的作用范围是**某一具体进程**。

## 文件系统抽象层VFS

文件系统抽象层是把不同文件系统的对外共性接口提取出来，形成一个函数指针数组，这样，通用文件系统访问接口层只需访问文件系统抽象层，而不需关心具体文件系统的实现细节和接口。

其实就是**基类**

### `file` & `dir` 接口
#### 1. struct file - 单个打开文件的描述符

**定义位置**：`kern/fs/file.h`

```c
/*
 * struct file - 描述一个进程打开的文件
 * 
 * 这个结构体不是指磁盘上的"文件"，而是描述"进程与它打开的文件之间的关系"
 * 存储在内核态内存中，仅当某个进程打开某个文件时才存在
 */
struct file {
    /*
     * status - 文件描述符的状态
     * - FD_NONE: 未使用（空闲）
     * - FD_INIT: 已初始化但未完全打开
     * - FD_OPENED: 已打开，可以进行读写操作
     * - FD_CLOSED: 已关闭
     */
    enum {
        FD_NONE, 
        FD_INIT, 
        FD_OPENED, 
        FD_CLOSED,
    } status;
    
    /*
     * readable - 是否可读
     * 根据打开文件时的标志（如 O_RDONLY, O_RDWR）设置
     */
    bool readable;
    
    /*
     * writable - 是否可写
     * 根据打开文件时的标志（如 O_WRONLY, O_RDWR）设置
     */
    bool writable;
    
    /*
     * fd - 文件描述符编号
     * 进程使用这个编号来引用打开的文件
     * 通常从 0 开始分配（0=stdin, 1=stdout, 2=stderr）
     */
    int fd;
    
    /*
     * pos - 当前读写位置（文件偏移量）
     * 记录下一次 read/write 操作从文件的哪个位置开始
     * 可以通过 lseek 系统调用修改
     */
    off_t pos;
    
    /*
     * node - 指向对应的 inode（索引节点）
     * inode 存储文件的元数据（大小、权限、数据块位置等）
     * 多个 file 可以指向同一个 inode（如 fork 后父子进程共享）
     */
    struct inode *node;
    
    /*
     * open_count - 打开计数（引用计数）
     * 记录有多少个进程/线程正在使用这个文件描述符
     * 当 open_count 降为 0 时，可以真正关闭文件
     */
    int open_count;
};

/*
 * 辅助函数：管理文件的引用计数
 */
static inline int fopen_count(struct file *file) {
    return file->open_count;
}

static inline int fopen_count_inc(struct file *file) {
    file->open_count += 1;
    return file->open_count;
}

static inline int fopen_count_dec(struct file *file) {
    file->open_count -= 1;
    return file->open_count;
}
```

**使用场景示例**：
```c
// 进程打开文件时
struct file *file = ...;
file->status = FD_OPENED;
file->readable = true;
file->writable = false;
file->fd = 3;              // 分配的文件描述符编号
file->pos = 0;             // 从文件开头开始
file->node = inode;        // 指向文件的 inode
file->open_count = 1;      // 初始引用计数为 1

// 进程 fork 后，子进程继承父进程的文件描述符
fopen_count_inc(file);     // 引用计数增加到 2

// 进程 read 文件
read(file->fd, buffer, 100);
file->pos += 100;          // 读取后，文件位置向后移动

// 进程 close 文件
fopen_count_dec(file);     // 引用计数减少
if (fopen_count(file) == 0) {
    // 没有进程使用这个文件了，可以真正关闭
    file->status = FD_CLOSED;
}
```

---

#### 2. struct files_struct - 进程的文件描述符表

**定义位置**：`kern/fs/fs.h`

```c
/*
 * struct files_struct - 进程的文件相关信息
 * 
 * 每个进程都有一个 files_struct，用于管理该进程打开的所有文件
 * 相当于进程的"文件描述符表"
 */
struct files_struct {
    /*
     * pwd - 当前工作目录（Present Working Directory）
     * 
     * 指向当前工作目录的 inode
     * 当用户执行相对路径命令时（如 "cd .."），需要用到这个字段
     * 例如：用户执行 "open("test.txt")", 需要相对于 pwd 来解析路径
     */
    struct inode *pwd;
    
    /*
     * fd_array - 文件描述符数组
     * 
     * 动态分配的数组，存储该进程打开的所有文件
     * 数组下标就是文件描述符编号（fd）
     * 
     * 例如：fd_array[3] 存储文件描述符 3 对应的 file 结构体
     * 
     * 标准文件描述符：
     * - fd_array[0]: stdin（标准输入）
     * - fd_array[1]: stdout（标准输出）
     * - fd_array[2]: stderr（标准错误）
     */
    struct file *fd_array;
    
    /*
     * files_count - 引用计数
     * 
     * 记录有多少个进程共享这个 files_struct
     * 通常情况下每个进程有独立的 files_struct（files_count = 1）
     * 
     * 特殊情况：
     * - fork 后，如果使用 CLONE_FILES 标志，父子进程共享 files_struct
     * - 多个线程共享同一个进程的 files_struct
     */
    int files_count;
    
    /*
     * files_sem - 信号量（锁）
     * 
     * 保护 files_struct 的并发访问
     * 当多个线程同时打开/关闭文件时，需要加锁保证数据一致性
     * 
     * 使用方式：
     * - lock_files(filesp): 获取锁
     * - unlock_files(filesp): 释放锁
     */
    semaphore_t files_sem;
};

/*
 * 计算文件描述符数组的大小
 * 
 * FILES_STRUCT_BUFSIZE: 一个页面去掉 files_struct 结构体自身后的剩余空间
 * FILES_STRUCT_NENTRY: 剩余空间能存储多少个 file 结构体
 * 
 * 这样设计的好处：
 * - files_struct 和 fd_array 分配在同一个页面内，减少内存碎片
 * - 每个进程的文件描述符数量有上限（约 100+ 个，取决于结构体大小）
 */
#define FILES_STRUCT_BUFSIZE    (PGSIZE - sizeof(struct files_struct))
#define FILES_STRUCT_NENTRY     (FILES_STRUCT_BUFSIZE / sizeof(struct file))

/*
 * 辅助函数：管理 files_struct 的引用计数
 */
static inline int files_count(struct files_struct *filesp) {
    return filesp->files_count;
}

static inline int files_count_inc(struct files_struct *filesp) {
    filesp->files_count += 1;
    return filesp->files_count;
}

static inline int files_count_dec(struct files_struct *filesp) {
    filesp->files_count -= 1;
    return filesp->files_count;
}

/*
 * 锁操作函数
 */
void lock_files(struct files_struct *filesp);    // 获取锁
void unlock_files(struct files_struct *filesp);  // 释放锁
```

**内存布局示意**：
```
一个页面（4KB）的内存布局：
┌─────────────────────────────────────┐
│  struct files_struct                │  固定大小（约 32 字节）
│  - pwd                              │
│  - fd_array (指针)                  │
│  - files_count                      │
│  - files_sem                        │
├─────────────────────────────────────┤
│  struct file fd_array[0]            │  每个约 40 字节
│  struct file fd_array[1]            │
│  struct file fd_array[2]            │
│  ...                                │
│  struct file fd_array[N]            │  N = FILES_STRUCT_NENTRY
└─────────────────────────────────────┘
总大小 = PGSIZE (4096 字节)
```

**使用场景示例**：
```c
// 1. 创建进程时，分配 files_struct
struct files_struct *filesp = files_create();
filesp->pwd = root_inode;              // 设置当前目录为根目录
filesp->files_count = 1;               // 初始引用计数为 1
sem_init(&filesp->files_sem, 1);       // 初始化信号量

// 2. 打开标准输入输出
filesp->fd_array[0].status = FD_OPENED;   // stdin
filesp->fd_array[0].readable = true;
filesp->fd_array[1].status = FD_OPENED;   // stdout
filesp->fd_array[1].writable = true;
filesp->fd_array[2].status = FD_OPENED;   // stderr
filesp->fd_array[2].writable = true;

// 3. 用户打开文件
int fd = file_open("test.txt", O_RDWR);
// 内部实现：
lock_files(filesp);
for (int i = 3; i < FILES_STRUCT_NENTRY; i++) {
    if (filesp->fd_array[i].status == FD_NONE) {
        // 找到空闲的文件描述符
        filesp->fd_array[i].status = FD_OPENED;
        filesp->fd_array[i].fd = i;
        filesp->fd_array[i].node = inode;
        fd = i;
        break;
    }
}
unlock_files(filesp);

// 4. fork 时复制文件描述符表
struct files_struct *child_filesp = files_create();
dup_files(child_filesp, parent_filesp);  // 复制所有打开的文件
// 或者共享文件描述符表（CLONE_FILES）
files_count_inc(parent_filesp);          // 引用计数+1
child->filesp = parent_filesp;           // 子进程指向父进程的 filesp

// 5. 进程退出时，清理文件描述符表
files_count_dec(filesp);
if (files_count(filesp) == 0) {
    // 没有进程使用这个 files_struct 了
    files_closeall(filesp);   // 关闭所有打开的文件
    files_destroy(filesp);    // 释放内存
}
```

---

### 3. 关系图解

```
进程 (struct proc_struct)
  │
  ├─ mm (内存管理)
  │
  └─ filesp (文件管理) ──────┐
                              │
                              ▼
                    struct files_struct
                    ┌─────────────────────────┐
                    │ pwd: 当前工作目录        │
                    │ fd_array: 文件描述符数组 │ ───┐
                    │ files_count: 引用计数    │    │
                    │ files_sem: 锁            │    │
                    └─────────────────────────┘    │
                                                    │
                    ┌───────────────────────────────┘
                    │
                    ▼
        fd_array: struct file[]
        ┌─────────────────────────┐
        │ [0] stdin  (status, fd, pos, node, ...)  │ ──→ inode (设备)
        │ [1] stdout (status, fd, pos, node, ...)  │ ──→ inode (设备)
        │ [2] stderr (status, fd, pos, node, ...)  │ ──→ inode (设备)
        │ [3] test.txt (status, fd, pos, node, ...) │ ──→ inode (文件)
        │ [4] (空闲) FD_NONE                       │
        │ ...                                      │
        └─────────────────────────────────────────┘
                                                    │
                                                    ▼
                                            struct inode
                                            ┌──────────────────┐
                                            │ 文件大小          │
                                            │ 文件权限          │
                                            │ 数据块位置        │
                                            │ ...              │
                                            └──────────────────┘
```

---

### 4. 核心操作流程

#### （1）打开文件 `open("test.txt", O_RDWR)`
```
1. 用户态：调用 open() 库函数
2. 进入内核：sys_open() 系统调用
3. 文件系统层：file_open()
   ├─ 查找空闲的 fd（遍历 fd_array）
   ├─ 解析路径找到 inode（相对于 pwd）
   ├─ 检查权限
   ├─ 初始化 file 结构体
   │  - status = FD_OPENED
   │  - fd = 分配的编号
   │  - pos = 0
   │  - node = inode
   │  - readable/writable 根据标志设置
   └─ 返回 fd 给用户
```

#### （2）读文件 `read(fd, buffer, size)`
```
1. 根据 fd 找到 file: file = filesp->fd_array[fd]
2. 检查 file->readable
3. 从 file->pos 位置读取数据（通过 file->node 访问磁盘）
4. 更新 file->pos += 实际读取的字节数
5. 返回读取的字节数
```

#### （3）关闭文件 `close(fd)`
```
1. 找到 file: file = filesp->fd_array[fd]
2. fopen_count_dec(file)
3. 如果 open_count == 0:
   ├─ file->status = FD_CLOSED
   └─ 释放相关资源
4. 标记 fd 为空闲（FD_NONE）
```

#### （4）fork 后文件描述符的继承
```
父进程：
filesp->fd_array[3] = {status=FD_OPENED, fd=3, pos=100, node=inode_A, open_count=1}

fork():
1. 子进程创建新的 files_struct
2. dup_files(child_filesp, parent_filesp)
   ├─ 复制每个已打开的文件
   └─ 增加每个 file 的 open_count

结果：
父进程：fd_array[3].open_count = 2
子进程：fd_array[3].open_count = 2 (指向同一个 file 和 inode)

父子进程共享：
- 文件读写位置 (pos)
- 打开标志 (readable/writable)
- 指向同一个 inode

父子进程独立：
- 各自的 files_struct
- 各自可以独立 close，不影响对方（直到 open_count 降为 0）
```

---


