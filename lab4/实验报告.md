# 练习1：分配并初始化一个进程控制块（需要编码）

## 设计实现过程

在`alloc_proc`函数中，我们需要初始化`proc_struct`结构体的所有字段。该函数负责分配并返回一个新的进程控制块，用于存储新建立的内核线程的管理信息。

### 实现代码

```c
static struct proc_struct *
alloc_proc(void)
{
    struct proc_struct *proc = kmalloc(sizeof(struct proc_struct));
    if (proc != NULL)
    {
        proc->state = PROC_UNINIT;                     // 设置进程为未初始化状态
        proc->pid = -1;                                // 未分配PID
        proc->runs = 0;                                // 运行次数初始化为0
        proc->kstack = 0;                              // 内核栈地址初始化为0
        proc->need_resched = 0;                        // 不需要调度
        proc->parent = NULL;                           // 父进程为空
        proc->mm = NULL;                               // 内存管理结构为空
        memset(&(proc->context), 0, sizeof(struct context)); // 初始化上下文
        proc->tf = NULL;                               // 中断帧指针为空
        proc->pgdir = boot_pgdir_pa;                   // 页目录为内核页目录的物理地址
        proc->flags = 0;                               // 标志位为0
        memset(proc->name, 0, PROC_NAME_LEN + 1);      // 进程名初始化为0
    }
    return proc;
}
```

### 各字段初始化说明

1. **state**: 设置为`PROC_UNINIT`（未初始化状态），表示进程刚创建，还未完成初始化
2. **pid**: 设置为-1，表示尚未分配进程ID，将在`do_fork`中通过`get_pid()`分配
3. **runs**: 设置为0，表示进程还未运行过
4. **kstack**: 设置为0，内核栈地址将在`setup_kstack`中分配
5. **need_resched**: 设置为0，表示不需要立即调度
6. **parent**: 设置为NULL，父进程将在`do_fork`中设置为`current`
7. **mm**: 设置为NULL，内存管理结构（本实验中内核线程不需要）
8. **context**: 清零，进程上下文将在`copy_thread`中设置
9. **tf**: 设置为NULL，中断帧指针将在`copy_thread`中设置
10. **pgdir**: 设置为`boot_pgdir_pa`，使用内核页目录
11. **flags**: 设置为0，进程标志位
12. **name**: 清零，进程名称将通过`set_proc_name`设置

## 问题回答

### 请说明proc_struct中struct context context和struct trapframe *tf成员变量含义和在本实验中的作用是啥？

#### struct context context（进程上下文）

**含义**：
- `context`保存了进程切换时需要保存和恢复的寄存器状态
- 在RISC-V中，包含ra（返回地址）、sp（栈指针）和s0-s11（被调用者保存寄存器）共14个寄存器

**作用**：
1. **进程切换**：在`switch_to()`函数中，通过保存当前进程的context并恢复下一个进程的context来实现进程切换
2. **断点续传**：当进程被切换出CPU后，其运行状态保存在context中；再次调度时，从context恢复继续运行
3. **轻量级保存**：相比trapframe，context只保存必要的callee-saved寄存器，切换开销较小

**在本实验中的具体使用**：
- 在`copy_thread()`中设置`proc->context.ra = (uintptr_t)forkret`，使得新进程第一次被调度时会执行`forkret`函数
- 在`copy_thread()`中设置`proc->context.sp = (uintptr_t)(proc->tf)`，指向trapframe的位置
- 在`proc_run()`中通过`switch_to(&(prev->context), &(next->context))`实现进程切换

#### struct trapframe *tf（中断帧指针）

**含义**：
- `tf`指向内核栈顶的trapframe结构，保存了进程在中断/异常发生时的完整处理器状态
- trapframe包含32个通用寄存器、status寄存器、epc（异常程序计数器）等，共34个字段

**作用**：
1. **中断处理**：当发生中断/异常时，硬件和软件协作将完整的处理器状态保存到trapframe
2. **首次执行**：对于新创建的进程，trapframe保存了其"首次执行"的初始状态
3. **系统调用**：保存用户态到内核态转换时的现场，以便返回用户态时恢复
4. **fork参数传递**：在`kernel_thread()`中构造临时trapframe，通过`do_fork()`传递给子进程

**在本实验中的具体使用**：
- 在`kernel_thread()`中构造临时trapframe，设置：
  - `tf.gpr.s0 = (uintptr_t)fn`：将函数指针保存在s0寄存器
  - `tf.gpr.s1 = (uintptr_t)arg`：将参数保存在s1寄存器
  - `tf.epc = (uintptr_t)kernel_thread_entry`：设置入口点为`kernel_thread_entry`
- 在`copy_thread()`中：
  - 将临时trapframe复制到进程内核栈顶：`*(proc->tf) = *tf`
  - 设置子进程返回值：`proc->tf->gpr.a0 = 0`
  - 设置栈指针：`proc->tf->gpr.sp = esp`
- 在`forkrets()`中通过`sret`指令从trapframe恢复，使新进程开始执行

#### 两者的区别与联系

| 特性 | context | trapframe |
|------|---------|-----------|
| 大小 | 14个寄存器 | 34个字段（32个通用寄存器+status+epc等） |
| 保存时机 | 进程主动切换（`switch_to`） | 中断/异常发生时 |
| 保存位置 | PCB内部 | 内核栈顶 |
| 用途 | 进程切换的上下文保存 | 中断处理、进程首次执行的完整状态 |
| 恢复方式 | 软件恢复（switch.S） | `sret`指令恢复 |

**联系**：
- 新进程首次执行：`switch_to`恢复context → 跳转到`forkret` → 调用`forkrets` → 执行`sret`从trapframe恢复 → 跳转到`kernel_thread_entry`
- context的sp字段指向trapframe，建立了两者的连接

# 练习2：为新创建的内核线程分配资源（需要编码）

## 设计实现过程

`do_fork`函数负责创建一个新的内核线程，它是进程创建的核心函数。该函数需要完成资源分配、状态复制、进程注册等一系列操作。

### 实现代码

```c
int do_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf)
{
    int ret = -E_NO_FREE_PROC;
    struct proc_struct *proc;
    if (nr_process >= MAX_PROCESS)
    {
        goto fork_out;
    }
    ret = -E_NO_MEM;
    
    // 1. 调用alloc_proc分配一个proc_struct
    if ((proc = alloc_proc()) == NULL) {
        goto fork_out;
    }
    
    // 设置父进程
    proc->parent = current;
    
    // 2. 调用setup_kstack为子进程分配内核栈
    if (setup_kstack(proc) != 0) {
        goto bad_fork_cleanup_proc;
    }
    
    // 3. 调用copy_mm根据clone_flag复制或共享内存管理信息
    if (copy_mm(clone_flags, proc) != 0) {
        goto bad_fork_cleanup_kstack;
    }
    
    // 4. 调用copy_thread在proc_struct中设置tf和context
    copy_thread(proc, stack, tf);
    
    // 5. 将proc_struct插入hash_list和proc_list
    bool intr_flag;
    local_intr_save(intr_flag);  // 关中断，保证原子操作
    {
        proc->pid = get_pid();     // 分配PID
        hash_proc(proc);           // 加入hash表
        list_add(&proc_list, &(proc->list_link)); // 加入进程链表
        nr_process++;              // 进程数加1
    }
    local_intr_restore(intr_flag); // 开中断
    
    // 6. 调用wakeup_proc使新进程变为RUNNABLE
    wakeup_proc(proc);
    
    // 7. 使用子进程的pid设置返回值
    ret = proc->pid;
    
fork_out:
    return ret;

bad_fork_cleanup_kstack:
    put_kstack(proc);
bad_fork_cleanup_proc:
    kfree(proc);
    goto fork_out;
}
```

### 实现步骤详解

#### 步骤1：分配进程控制块
```c
if ((proc = alloc_proc()) == NULL) {
    goto fork_out;
}
proc->parent = current;
```
- 调用`alloc_proc()`分配并初始化一个新的PCB
- 设置父进程为当前进程`current`
- 如果分配失败，跳转到`fork_out`返回错误

#### 步骤2：分配内核栈
```c
if (setup_kstack(proc) != 0) {
    goto bad_fork_cleanup_proc;
}
```
- 调用`setup_kstack()`为子进程分配KSTACKPAGE（2页，8KB）的内核栈
- 如果分配失败，跳转到`bad_fork_cleanup_proc`释放PCB

#### 步骤3：复制内存管理信息
```c
if (copy_mm(clone_flags, proc) != 0) {
    goto bad_fork_cleanup_kstack;
}
```
- 根据`clone_flags`决定是复制还是共享内存空间
- 对于内核线程，`mm`为NULL，此函数实际不做操作
- 如果失败，跳转到`bad_fork_cleanup_kstack`释放内核栈和PCB

#### 步骤4：设置trapframe和context
```c
copy_thread(proc, stack, tf);
```
- 将父进程的trapframe复制到子进程内核栈顶
- 设置子进程的context，使其首次调度时执行`forkret`
- 设置子进程的返回值a0为0（区分父子进程）

#### 步骤5：加入进程管理结构
```c
bool intr_flag;
local_intr_save(intr_flag);  // 关中断，保证原子操作
{
    proc->pid = get_pid();     // 分配PID
    hash_proc(proc);           // 加入hash表
    list_add(&proc_list, &(proc->list_link)); // 加入进程链表
    nr_process++;              // 进程数加1
}
local_intr_restore(intr_flag); // 开中断
```
- **关中断**：保证PID分配、加入链表等操作的原子性
- **分配PID**：调用`get_pid()`获取唯一的进程ID
- **加入hash表**：通过`hash_proc()`将进程加入以PID为key的哈希表，便于快速查找
- **加入进程链表**：将进程加入全局进程链表`proc_list`
- **更新计数**：`nr_process++`记录系统中的进程总数
- **开中断**：恢复中断状态

#### 步骤6：唤醒新进程
```c
wakeup_proc(proc);
```
- 将进程状态设置为`PROC_RUNNABLE`，使其可以被调度执行

#### 步骤7：返回子进程PID
```c
ret = proc->pid;
```
- 父进程返回子进程的PID
- 子进程返回0（在`copy_thread`中设置的`tf->gpr.a0 = 0`）

### 错误处理机制

采用三级清理策略，确保资源正确释放：

1. **fork_out**：进程数超限或alloc_proc失败时直接返回错误码
2. **bad_fork_cleanup_kstack**：释放已分配的内核栈，然后执行下一级清理
3. **bad_fork_cleanup_proc**：释放PCB内存

## 问题回答

### 请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。

**答案：是的，ucore能够保证给每个新fork的线程分配唯一的ID。**

#### 分析理由

**1. get_pid()函数的设计保证唯一性**

```c
static int get_pid(void)
{
    static_assert(MAX_PID > MAX_PROCESS);
    struct proc_struct *proc;
    list_entry_t *list = &proc_list, *le;
    static int next_safe = MAX_PID, last_pid = MAX_PID;
    
    if (++last_pid >= MAX_PID)
    {
        last_pid = 1;
        goto inside;
    }
    if (last_pid >= next_safe)
    {
    inside:
        next_safe = MAX_PID;
    repeat:
        le = list;
        while ((le = list_next(le)) != list)
        {
            proc = le2proc(le, list_link);
            if (proc->pid == last_pid)
            {
                if (++last_pid >= next_safe)
                {
                    if (last_pid >= MAX_PID)
                    {
                        last_pid = 1;
                    }
                    next_safe = MAX_PID;
                    goto repeat;
                }
            }
            else if (proc->pid > last_pid && next_safe > proc->pid)
            {
                next_safe = proc->pid;
            }
        }
    }
    return last_pid;
}
```

该函数采用了以下机制保证PID唯一：

**a) 递增分配策略**
- 使用静态变量`last_pid`记录上次分配的PID
- 每次调用时先递增：`++last_pid`
- 从1开始循环使用PID（0保留给idle进程）

**b) 冲突检测机制**
- 当`last_pid >= next_safe`时，需要检查是否与现有进程冲突
- 遍历整个进程链表`proc_list`，检查是否有进程使用了`last_pid`
- 如果冲突，继续递增直到找到未被使用的PID

**c) 优化的区间检测**
- `next_safe`变量记录下一个"需要检查冲突"的位置
- 在`[last_pid, next_safe)`区间内的PID保证未被使用，无需检查
- 这样避免了每次都遍历整个进程链表，提高了效率

**2. 原子操作保护**

在`do_fork()`中，PID分配和进程加入链表的操作被放在临界区保护：

```c
bool intr_flag;
local_intr_save(intr_flag);  // 关中断
{
    proc->pid = get_pid();     // 分配PID
    hash_proc(proc);           // 加入hash表
    list_add(&proc_list, &(proc->list_link)); // 加入进程链表
    nr_process++;
}
local_intr_restore(intr_flag); // 开中断
```

**保护意义**：
- **防止并发冲突**：关中断期间不会发生进程切换，保证get_pid()、hash_proc()、list_add()是原子操作
- **一致性保证**：PID分配和进程注册必须作为一个整体完成，避免出现"PID已分配但进程未注册"的中间状态
- **避免重复分配**：两个进程不会同时调用get_pid()获得相同的PID

**3. 哈希表快速查找**

系统通过`hash_list[HASH_LIST_SIZE]`哈希表管理进程：

```c
#define HASH_SHIFT 10
#define HASH_LIST_SIZE (1 << HASH_SHIFT)  // 1024
#define pid_hashfn(x) (hash32(x, HASH_SHIFT))

static void hash_proc(struct proc_struct *proc)
{
    list_add(hash_list + pid_hashfn(proc->pid), &(proc->hash_link));
}

struct proc_struct *find_proc(int pid)
{
    if (0 < pid && pid < MAX_PID)
    {
        list_entry_t *list = hash_list + pid_hashfn(pid), *le = list;
        while ((le = list_next(le)) != list)
        {
            struct proc_struct *proc = le2proc(le, hash_link);
            if (proc->pid == pid)
            {
                return proc;
            }
        }
    }
    return NULL;
}
```

**作用**：
- 提供O(1)平均复杂度的PID查找
- `find_proc()`可以快速验证某个PID是否已被使用
- 如果PID有重复，通过哈希表会立即发现

**4. 静态断言保证**

代码中有编译期检查：
```c
static_assert(MAX_PID > MAX_PROCESS);
```

确保PID空间大于最大进程数，理论上不会出现"无可用PID"的情况。

#### 结论

ucore通过以下四重机制保证每个新fork的线程获得唯一的ID：

1. **get_pid()的智能分配算法**：递增+冲突检测+区间优化
2. **原子操作保护**：关中断保证分配和注册的原子性
3. **哈希表管理**：快速查找和验证PID唯一性
4. **编译期检查**：确保PID空间足够大

这套机制既保证了正确性（唯一性），又兼顾了效率（避免每次都遍历全部进程）。

# 练习3：编写proc_run 函数（需要编码）

## 设计实现过程

`proc_run`函数负责将指定的进程切换到CPU上运行，实现进程调度的核心功能。

### 实现代码

```c
void proc_run(struct proc_struct *proc)
{
    if (proc != current)
    {
        bool intr_flag;
        struct proc_struct *prev = current, *next = proc;
        
        // 1. 禁用中断
        local_intr_save(intr_flag);
        {
            // 2. 切换当前进程为要运行的进程
            current = proc;
            
            // 3. 切换页表，使用新进程的地址空间
            lsatp(next->pgdir);
            
            // 4. 上下文切换
            switch_to(&(prev->context), &(next->context));
        }
        // 5. 允许中断
        local_intr_restore(intr_flag);
    }
}
```

### 实现步骤详解

#### 步骤0：检查是否需要切换
```c
if (proc != current)
```
- 如果要切换的进程就是当前进程，直接返回，无需切换
- 避免不必要的开销

#### 步骤1：禁用中断
```c
bool intr_flag;
local_intr_save(intr_flag);
```
- 保存当前中断状态到`intr_flag`
- 关闭中断，确保进程切换过程不被打断
- **必要性**：进程切换是临界区操作，如果被中断可能导致状态不一致

#### 步骤2：切换当前进程指针
```c
struct proc_struct *prev = current, *next = proc;
current = proc;
```
- 保存切换前后的进程指针，供`switch_to`使用
- 更新全局变量`current`指向新进程
- 此后系统认为新进程已经是"当前进程"

#### 步骤3：切换页表
```c
lsatp(next->pgdir);
```
- 修改SATP寄存器，加载新进程的页目录基址
- RISC-V的SATP（Supervisor Address Translation and Protection）寄存器控制页表
- **作用**：切换到新进程的虚拟地址空间
- **注意**：在本实验中，所有内核线程共享内核地址空间，`pgdir`都是`boot_pgdir_pa`，实际未发生切换

#### 步骤4：上下文切换
```c
switch_to(&(prev->context), &(next->context));
```
- 调用汇编函数`switch_to`（定义在switch.S中）
- **保存旧进程context**：将当前CPU寄存器（ra, sp, s0-s11）保存到`prev->context`
- **恢复新进程context**：从`next->context`恢复寄存器状态
- **关键**：执行`ret`指令跳转到`next->context.ra`，即新进程上次被换出的位置（或首次执行的`forkret`）

#### 步骤5：允许中断
```c
local_intr_restore(intr_flag);
```
- 恢复之前保存的中断状态
- 重新允许中断响应

### switch_to函数分析

虽然我们没有编写`switch_to`，但理解其工作原理很重要：

```asm
# switch_to(from, to)
# a0: from (prev->context)
# a1: to   (next->context)

switch_to:
    # 保存prev的context
    sd ra, 0(a0)
    sd sp, 8(a0)
    sd s0, 16(a0)
    sd s1, 24(a0)
    sd s2, 32(a0)
    sd s3, 40(a0)
    sd s4, 48(a0)
    sd s5, 56(a0)
    sd s6, 64(a0)
    sd s7, 72(a0)
    sd s8, 80(a0)
    sd s9, 88(a0)
    sd s10, 96(a0)
    sd s11, 104(a0)
    
    # 恢复next的context
    ld ra, 0(a1)
    ld sp, 8(a1)
    ld s0, 16(a1)
    ld s1, 24(a1)
    ld s2, 32(a1)
    ld s3, 40(a1)
    ld s4, 48(a1)
    ld s5, 56(a1)
    ld s6, 64(a1)
    ld s7, 72(a1)
    ld s8, 80(a1)
    ld s9, 88(a1)
    ld s10, 96(a1)
    ld s11, 104(a1)
    
    ret  # 跳转到ra（next->context.ra）
```

- **保存14个寄存器**：ra（返回地址）、sp（栈指针）、s0-s11（callee-saved寄存器）
- **恢复14个寄存器**：从新进程的context中加载
- **ret指令**：跳转到新进程的ra，实现控制流切换

### 进程切换流程图

```
当前进程A正在运行
    |
    | 触发调度（如时间片用完）
    v
schedule()  ← 调度器选择下一个进程B
    |
    v
proc_run(B)
    |
    ├─→ if (B != current) ?  ──No──→ return
    |       ↓ Yes
    ├─→ local_intr_save()  // 关中断
    |
    ├─→ current = B        // 更新当前进程指针
    |
    ├─→ lsatp(B->pgdir)    // 切换页表
    |
    ├─→ switch_to(&A->context, &B->context)
    |       |
    |       ├─→ 保存A的ra, sp, s0-s11到A->context
    |       ├─→ 恢复B的ra, sp, s0-s11从B->context
    |       └─→ ret跳转到B->context.ra
    |
    |   [此时CPU已经在运行进程B的代码]
    |
    ├─→ local_intr_restore()  // 开中断
    |
    v
进程B继续运行
```

### 新进程首次执行的特殊流程

对于新创建的进程，首次执行时的流程有所不同：

1. **copy_thread设置context**：
   ```c
   proc->context.ra = (uintptr_t)forkret;
   proc->context.sp = (uintptr_t)(proc->tf);
   ```

2. **首次调度**：
   ```
   proc_run(new_proc)
       → switch_to(..., &new_proc->context)
       → ret跳转到forkret
   ```

3. **forkret → forkrets → sret**：
   ```c
   static void forkret(void) {
       forkrets(current->tf);
   }
   ```
   
   `forkrets`执行`sret`从trapframe恢复，跳转到`tf->epc`（即`kernel_thread_entry`）

4. **kernel_thread_entry**：
   ```asm
   kernel_thread_entry:
       move a0, s1        # arg → a0
       jalr s0            # 调用fn(arg)
       jal do_exit        # 退出
   ```

完整流程：
```
proc_run → switch_to → forkret → forkrets → sret → kernel_thread_entry → fn(arg)
```

## 问题回答

### 在本实验的执行过程中，创建且运行了几个内核线程？

**答案：创建并运行了2个内核线程。**

#### 详细分析

**1. idleproc（idle线程，PID=0）**

**创建位置**：`proc_init()`函数中
```c
void proc_init(void)
{
    // ...
    
    if ((idleproc = alloc_proc()) == NULL)
    {
        panic("cannot alloc idleproc.\n");
    }
    
    idleproc->pid = 0;
    idleproc->state = PROC_RUNNABLE;
    idleproc->kstack = (uintptr_t)bootstack;
    idleproc->need_resched = 1;
    set_proc_name(idleproc, "idle");
    nr_process++;
    
    current = idleproc;
    
    // ...
}
```

**特点**：
- **第0号进程**：PID为0，是系统中第一个被创建的进程
- **手工创建**：不是通过`do_fork`创建，而是在`proc_init`中直接初始化
- **特殊用途**：是操作系统的"空闲进程"
- **使用bootstack**：使用启动时的内核栈，不需要分配新的栈空间
- **永不退出**：执行`cpu_idle()`无限循环，等待调度其他进程

**运行位置**：`cpu_idle()`函数
```c
void cpu_idle(void)
{
    while (1)
    {
        if (current->need_resched)
        {
            schedule();
        }
    }
}
```

**作用**：
- 当没有其他进程需要运行时，CPU执行idle进程
- 检查`need_resched`标志，触发进程调度
- 保证CPU始终有进程在运行

**2. initproc（init线程，PID=1）**

**创建位置**：`proc_init()`函数中，通过`kernel_thread`创建
```c
void proc_init(void)
{
    // ...
    
    current = idleproc;
    
    int pid = kernel_thread(init_main, "Hello world!!", 0);
    if (pid <= 0)
    {
        panic("create init_main failed.\n");
    }
    
    initproc = find_proc(pid);
    set_proc_name(initproc, "init");
    
    // ...
}
```

**创建过程**：
1. 调用`kernel_thread(init_main, "Hello world!!", 0)`
2. `kernel_thread`构造trapframe并调用`do_fork`
3. `do_fork`完成进程创建的七个步骤
4. 返回新进程的PID（应为1）
5. 通过`find_proc(pid)`找到新创建的进程
6. 设置进程名为"init"

**特点**：
- **第1号进程**：PID为1，是系统中第一个通过正常流程创建的进程
- **标准创建**：通过`kernel_thread` → `do_fork`创建
- **有独立内核栈**：在`do_fork`中通过`setup_kstack`分配
- **执行init_main**：入口函数为`init_main`

**执行的函数**：`init_main()`
```c
static int init_main(void *arg)
{
    cprintf("this initproc, pid = %d, name = \"%s\"\n", current->pid, get_proc_name(current));
    cprintf("To U: \"%s\".\n", (const char *)arg);
    cprintf("To U: \"en.., Bye, Bye. :)\"\n");
    return 0;
}
```

**输出**：
```
this initproc, pid = 1, name = "init"
To U: "Hello world!!".
To U: "en.., Bye, Bye. :)"
```

**作用**：
- 作为第一个用户进程的父进程（在后续实验中）
- 本实验中只是打印信息然后退出

#### 进程创建时间线

```
kern_init()
    |
    v
proc_init()
    |
    ├─→ 手工创建idleproc（PID=0）
    |       - alloc_proc()
    |       - 手动设置pid、state、kstack等
    |       - current = idleproc
    |
    ├─→ 通过kernel_thread创建initproc（PID=1）
    |       - kernel_thread(init_main, ...)
    |           → 构造trapframe
    |           → do_fork()
    |               - alloc_proc()
    |               - setup_kstack()
    |               - copy_mm()
    |               - copy_thread()
    |               - 分配PID=1
    |               - hash_proc() & list_add()
    |               - wakeup_proc() → state = PROC_RUNNABLE
    |       - find_proc(1)
    |       - set_proc_name("init")
    |
    v
proc_init()返回到kern_init()
    |
    v
cpu_idle()  ← idleproc执行此函数
    |
    | idleproc->need_resched == 1
    v
schedule()  ← 调度器选择initproc
    |
    v
proc_run(initproc)
    |
    ├─→ switch_to(&idleproc->context, &initproc->context)
    |
    v
initproc开始执行
    |
    ├─→ forkret() → forkrets() → sret
    |
    ├─→ kernel_thread_entry
    |       - move a0, s1  (arg = "Hello world!!")
    |       - jalr s0      (call init_main)
    |
    v
init_main("Hello world!!")
    |
    ├─→ 打印信息
    |
    v
返回到kernel_thread_entry
    |
    v
jal do_exit  ← 进程退出
```

#### 进程状态总结

| 进程名 | PID | 创建方式 | 入口函数 | 主要作用 |
|--------|-----|----------|----------|----------|
| idleproc | 0 | 手工创建 | cpu_idle | 空闲进程，CPU空闲时运行，触发调度 |
| initproc | 1 | kernel_thread + do_fork | init_main | 第一个正常创建的内核线程，打印信息 |

#### 运行顺序

1. **系统启动**：执行idleproc（在`kern_init`最后调用`cpu_idle()`）
2. **第一次调度**：idleproc的`need_resched=1`，触发`schedule()`
3. **切换到initproc**：通过`proc_run(initproc)`切换
4. **initproc运行**：执行`init_main()`打印信息
5. **initproc退出**：调用`do_exit()`（会panic，因为未实现）


所以本实验中共创建了**2个内核线程**：idleproc和initproc。

# 扩展练习 Challenge：
## 1.**说明语句``local_intr_save(intr_flag);....local_intr_restore(intr_flag);``是如何实现开关中断的？**
步骤1：local_intr_save(intr_flag)
```text
1. 调用 __intr_save()
2. 读取 sstatus.SIE 位
3. 如果 SIE=1（中断开启）：
   - 调用 intr_disable() 关闭中断
   - 返回 true 给 intr_flag
4. 如果 SIE=0（中断已关闭）：
   - 返回 false 给 intr_flag
```

步骤2：执行临界区代码
- 此时中断确定是关闭的
- 确保内存分配等操作的原子性

步骤3：local_intr_restore(intr_flag)
```text
1. 调用 __intr_restore(intr_flag)
2. 如果 intr_flag=true（之前中断是开启的）：
   - 调用 intr_enable() 重新开启中断
3. 如果 intr_flag=false（之前中断已是关闭的）：
   - 什么也不做，保持中断关闭状态
```
**设计优势**
状态保持：不是简单地在结束时开启中断，而是精确恢复到进入临界区之前的状态
支持嵌套的临界区保护

## 2.**深入理解不同分页模式的工作原理（思考题）**
get_pte()函数（位于kern/mm/pmm.c）用于在页表中查找或创建页表项，从而实现对指定线性地址对应的物理页的访问和映射操作。这在操作系统中的分页机制下，是实现虚拟内存与物理内存之间映射关系非常重要的内容。

### get_pte()函数中有两段形式类似的代码， 结合sv32，sv39，sv48的异同，解释这两段代码为什么如此相像？
#### SV39/SV48/SV32 的相同设计理念
这三种RISC-V页表格式都采用**递归的树状结构**：
- SV32：2级页表（10位 + 10位 + 12位偏移）
- SV39：3级页表（9位 × 3 + 12位偏移）
- SV48：4级页表（9位 × 4 + 12位偏移）

**关键洞察**：无论多少级，每一级的查找和分配逻辑都是相同的：
1. 用当前级别的索引找到页表项
2. 检查有效位(PTE_V)
3. 如果不存在且需要创建，就分配新页表
4. 进入下一级

### 目前get_pte()函数将页表项的查找和页表项的分配合并在一个函数里，你认为这种写法好吗？有没有必要把两个功能拆开？
将页表项的查找和分配功能合并在一个get_pte()函数中的设计，在当前操作系统的上下文中是合理且实用的，但从软件工程的角度看确实存在改进空间。

当前合并写法的优点：接口简单，调用方无需关心页表是否存在。只需通过一个函数调用就能获得可用的页表项，这符合"懒分配"的设计哲学——只有在实际需要时才创建页表结构，避免了预先分配所有页表带来的内存浪费。对于内核中频繁进行的页表操作，可以减少代码复杂度和出错可能性。

然而，这种设计也存在明显的缺点。首先是职责不单一，函数同时承担查询和创建两个不同层次的任务，违反了单一职责原则。这导致错误处理变得模糊——当返回NULL时，调用方无法区分是页表不存在但不需要创建，还是内存分配失败。其次，在只需要查询的场景下，函数仍然会执行不必要的参数检查和条件判断，造成性能浪费。此外，这种设计也不利于代码复用和测试，无法单独测试纯查询逻辑。

一个更优雅的设计是将功能拆分为find_pte()和create_pte()两个函数。find_pte()专注于纯查询，快速检查页表项是否存在；create_pte()负责页表的创建和初始化。这样不仅使每个函数的职责更加清晰，还能为不同使用场景提供更精确的接口。比如在页面错误处理中，可以先调用find_pte()确认缺失的页表，再根据需要调用create_pte()。这种拆分还能为未来的性能优化和功能扩展留下更大空间。

总的来说，当前的合并设计在简单性和实用性方面有其价值，特别适合初期的操作系统开发。但随着系统复杂度的增加，拆分成两个专注的函数会带来更好的可维护性、可测试性和性能特性。

