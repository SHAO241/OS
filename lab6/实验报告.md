# 练习1：理解调度器框架的实现（不需要编码）

## 请详细解释 sched_class 结构体中每个函数指针的作用和调用时机，分析为什么需要将这些函数定义为函数指针，而不是直接实现函数。

这是一个非常体现**软件工程思想**在操作系统内核中应用的问题。

`sched_class` 结构体本质上是 C 语言实现**面向对象编程（OOP）**中 **“接口（Interface）”** 或 **“纯虚类（Abstract Base Class）”** 的一种手段。

以下是详细的成员解析和设计哲学分析。

---

### 一、 `sched_class` 成员详解与调用时机

在 ucore 中，`sched_class` 通常定义如下（不同 Lab 版本略有差异，但核心一致）：

```c
struct sched_class {
    // 调度器的名字
    const char *name;
    // 初始化运行队列
    void (*init)(struct run_queue *rq);
    // 将进程加入就绪队列
    void (*enqueue)(struct run_queue *rq, struct proc_struct *proc);
    // 将进程从就绪队列移除
    void (*dequeue)(struct run_queue *rq, struct proc_struct *proc);
    // 挑选下一个要运行的进程
    struct proc_struct *(*pick_next)(struct run_queue *rq);
    // 处理时钟中断（更新时间片等）
    void (*proc_tick)(struct run_queue *rq, struct proc_struct *proc);
};

```

#### 1. `init`

* **作用**：初始化调度算法所需的全局数据结构。例如，对于 Round Robin (RR)，它初始化链表头；对于 Stride 或 CFS，它可能需要初始化红黑树或优先级队列。
* **调用时机**：**系统启动时**。在 `kern_init` -> `sched_init` 中被调用一次。

#### 2. `enqueue` (入队)

* **作用**：将一个处于 `PROC_RUNNABLE`（就绪）状态的进程，放入调度器管理的“就绪池”中。
* RR 算法：加到链表尾部。
* 优先级算法：根据优先级插入到对应队列。
* Stride/CFS：插入到红黑树或斜堆的正确位置。


* **调用时机**：
1. **进程被唤醒时** (`wakeup_proc`)：进程等待结束，准备好运行了。
2. **进程创建时** (`do_fork`)：新进程诞生，且需要立即运行。
3. **进程被抢占后** (`schedule`)：进程时间片用完，被强制剥夺 CPU，但它还没执行完，所以要重新排队等待下一次机会。



#### 3. `dequeue` (出队)

* **作用**：将一个进程从“就绪池”中移除。这意味着该进程不再处于“等待被调度”的状态（因为它要么马上要运行了，要么被阻塞了）。
* **调用时机**：
1. **调度器选中进程时** (`schedule`)：`pick_next` 挑中了它，它即将变成 `current`（运行中），自然不能留在就绪队列里。
2. **进程要移动时**：例如修改了优先级，可能需要先 dequeue，修改数值，再 enqueue。



#### 4. `pick_next` (挑选)

* **作用**：这是调度算法的**核心决策逻辑**。它回答“谁是下一个 CPU 使用者？”。它通常只返回指针，不负责移除队列（移除由 `dequeue` 负责）。
* RR 算法：返回链表头。
* Stride/CFS：返回步长最小或虚拟时间最小的节点。


* **调用时机**：**`schedule` 函数的核心处**。当 CPU 需要切换时调用。

#### 5. `proc_tick` (滴答)

* **作用**：由时钟中断触发，用于评估当前运行进程的状态。
* 更新统计信息（如剩余时间片 `time_slice` 减一）。
* 判断是否需要抢占（如果时间片归零，设置 `need_resched = 1`）。
* 处理优先级老化（Aging，防止饥饿）。


* **调用时机**：**每次硬件时钟中断发生时** (`trap_dispatch` -> `sched_class_proc_tick`)。这是唯一一个异步触发的函数。

---

### 二、 为什么要用函数指针？（设计哲学分析）

为什么不直接写死函数，比如直接调用 `RR_enqueue`，而是要通过 `sched_class->enqueue` 间接调用？

这体现了操作系统设计中的 **“策略与机制分离”（Separation of Policy and Mechanism）** 原则，以及 **多态性（Polymorphism）** 的应用。

#### 1. 实现“多态”与可插拔性 (Pluggability)

这是最主要的原因。操作系统需要支持多种调度算法，但内核核心逻辑（`schedule` 函数）不应该关心具体用的是哪种算法。

* **如果不使用函数指针（硬编码）：**
```c
void schedule() {
    // 噩梦般的写法
    #ifdef USE_RR
        RR_enqueue(current);
        next = RR_pick_next();
    #elif defined(USE_STRIDE)
        Stride_enqueue(current);
        next = Stride_pick_next();
    #elif defined(USE_CFS)
         // ...
    #endif
}

```


这种写法导致 `schedule` 函数与具体的算法**强耦合**。每当你写一个新的调度算法，都必须去修改内核核心代码，极易引入 Bug。
* **使用函数指针（接口）：**
内核只需要定义好 `sched_class` 接口。
```c
// 切换算法只需一行代码
sched_class = &Stride_sched_class; 

// 核心代码永远不需要变
sched_class->enqueue(current);

```


这就像 USB 接口，`schedule` 函数是电脑上的 USB 插槽，具体的算法（RR, Stride）是 U 盘或鼠标。只要符合 USB 标准，插谁都能用。

#### 2. 运行时动态切换 (Runtime Switching)

使用函数指针允许系统在**运行时**动态更换调度器，而不需要重新编译内核。

* 例如，Linux 内核支持这就绪队列中同时存在实时进程（使用 `RT` 调度类）和普通进程（使用 `CFS` 调度类）。内核可以根据进程类型，动态调用不同 `sched_class` 的指针，实现混合调度。

#### 3. 封装与模块化 (Encapsulation)

`sched_class` 强制调度算法开发者遵守统一的规范。

* 它定义了调度器**必须**做什么（init, enqueue, pick_next...）。
* 它隐藏了调度器**内部**怎么做（是用链表还是红黑树）。
* 这使得多人协作开发内核变得容易：一个人写核心框架，另一个人写具体的调度算法，互不干扰。



## 运行队列结构体 run_queue 的分析：比较lab5和lab6中run_queue 结构体的差异，解释为什么lab6的 run_queue 需要支持两种数据结构（链表和斜堆）。

lab5中就没有run_queue!!!
这是一个非常敏锐的问题。在 ucore Lab6 中，`run_queue` 结构体同时包含了一个链表头（`run_list`）和一个斜堆指针（`lab6_run_pool`），这看起来似乎是冗余的。

但这实际上是为了**兼容性**和**性能优化**而做的设计，目的是让同一个 `run_queue` 结构体能够支持多种不同的调度算法（Round Robin 和 Stride）。

以下是详细的三个原因：

### 1. 兼容性：支持默认的 Round Robin (RR) 算法

操作系统启动时，或者在某些 fallback 场景下，依然使用默认的 **Round Robin** 调度器。

* **RR 的需求**：RR 只需要一个简单的**双向链表**来实现 FIFO（先进先出）。
* **字段作用**：`run_list` 就是为此准备的。
* **如果不保留**：如果为了做 Lab6 把 `run_list` 删了，那么系统默认的 RR 调度器就会无法编译或运行，导致系统启动失败。

### 2. 性能：Stride 调度算法需要高效查找最小值



* **Stride 的逻辑**：每次必须选择 `pass`（步进值）**最小**的那个进程运行。
* **如果只用链表 (`run_list`)**：
* 要在链表中找到 `pass` 最小的进程，必须遍历整个链表。
* **时间复杂度**：。当进程数量多时，调度开销会随着进程数线性增长，效率极低。


* **引入斜堆 (`lab6_run_pool`)**：
* 斜堆（Skew Heap）是一种**优先队列**。它能自动维护顺序，让 `pass` 最小的进程始终位于堆顶（根节点）。
* **时间复杂度**：查找最小值是 ，插入和删除节点是 。
* **优势**：相比于链表的 ，斜堆在多进程场景下极其高效。



### 3. C 语言实现“多态”的妥协

在 C++ 或 Java 中，我们可以用继承来解决这个问题（比如 `RR_RunQueue` 和 `Stride_RunQueue` 继承自 `Base_RunQueue`）。但在 C 语言内核开发中，为了保持代码简单和内存布局统一，通常采用**“包含所有可能字段”**的策略。

`run_queue` 结构体本质上是一个**容器**，它为不同的算法提供了所需的存储空间：

```c
struct run_queue {
    // ---------------------------------
    // 通用部分
    // ---------------------------------
    int max_time_slice;
    unsigned int proc_num;

    // ---------------------------------
    // 专用于 Round Robin 算法的数据结构
    // ---------------------------------
    list_entry_t run_list; 

    // ---------------------------------
    // 专用于 Stride 算法的数据结构
    // ---------------------------------
    skew_heap_entry_t *lab6_run_pool; 
};

```

* **当使用 `RR_sched_class` 时**：调度器只操作 `run_list`，忽略 `lab6_run_pool`。
* **当使用 `Stride_sched_class` 时**：调度器主要操作 `lab6_run_pool`（用于排序和查找），有时也会维护 `run_list` 用于调试或统计。

### 总结

| 特性 | 链表 (`run_list`) | 斜堆 (`lab6_run_pool`) |
| --- | --- | --- |
| **服务对象** | Round Robin (RR) | Stride Scheduling |
| **核心操作** | 先进先出 (FIFO) | **取最小值 (Min-Pass)** |
| **查找效率** |  (遍历查找) | **(直接取根)** |
| **增删效率** |  (插尾/删头) |  (堆合并) |

## 调度器框架函数分析：分析 sched_init()、wakeup_proc() 和 schedule() 函数在lab6中的实现变化，理解这些函数如何与具体的调度算法解耦。


这三个函数的变化完整地展示了操作系统如何从**“硬编码调度”**（Lab5）演变为**“可插拔调度框架”**（Lab6）。

这种演变的目的是实现**机制（Mechanism）与策略（Policy）的分离**。

以下是逐个函数的深度对比分析：

### 1. 初始化：`sched_init()`

这是 Lab6 新增的关键初始化步骤，确立了“谁来负责调度”。

```c
void sched_init(void)
{
    list_init(&timer_list);

    // 1. 绑定策略：指定当前系统使用哪种算法（默认为 Round Robin）
    sched_class = &default_sched_class;

    // 2. 初始化容器：设置全局运行队列
    rq = &__rq;
    rq->max_time_slice = MAX_TIME_SLICE;
    
    // 3. 算法自举：调用具体算法的初始化函数（如 RR_init）
    sched_class->init(rq);

    cprintf("sched class: %s\n", sched_class->name);
}

```

* **分析**：
* Lab5 不需要这个函数，因为调度逻辑是写死的，没有“配置”的概念。
* Lab6 通过 `sched_class = &default_sched_class` 实现了**动态绑定**。内核其他部分只知道 `sched_class` 这个指针，根本不需要知道具体指向的是 RR 还是 Stride。如果想换算法，只需修改这一行指针赋值即可。



### 2. 唤醒进程：`wakeup_proc()`

这个函数的变化揭示了**就绪队列（Run Queue）** 的引入。

* **Lab 5 (状态变更即结束)**：
```c
proc->state = PROC_RUNNABLE; 
// 结束。因为 Lab5 的调度器会在全局链表中遍历所有进程，
// 只要状态改了，下次遍历就能看到它。

```


* **Lab 6 (状态变更 + 入队)**：
```c
proc->state = PROC_RUNNABLE;
if (proc != current) {
    // 【关键变化】显式调用调度类的方法，将进程放入“就绪池”
    sched_class_enqueue(proc); 
}

```


* **解耦分析**：
* **内核层（机制）**：负责感知“事件发生了，进程可以醒了”，并将进程状态设为 `RUNNABLE`。
* **调度层（策略）**：通过 `enqueue` 决定**“醒来的进程该放在哪？”**
* 如果是 RR，放在链表尾部。
* 如果是优先级调度，插队到高优先级队列。
* 如果是 Stride，插入斜堆。


* **为什么变了？** Lab6 的 `schedule` 不再遍历所有进程，只看 `run_queue`。如果 `wakeup` 时不入队，调度器永远看不到这个进程（即使它是 Runnable）。



### 3. 核心调度：`schedule()`

这是变化最大、最能体现解耦思想的地方。

* **Lab 5 (裁判员亲自下场找人)**：
```c
// 1. 笨拙的查找机制
// 只能在 proc_list 全局链表中，从 current 开始一个个往下问
do {
    le = list_next(le);
    next = le2proc(le, ...);
    // 2. 硬编码的策略 (FIFO/轮询)
    if (next->state == PROC_RUNNABLE) break; 
} while (le != last);

```


* **问题**：查找逻辑（怎么遍历）和选择逻辑（选谁）混在一起。如果你想改用“优先级”，你得把这整个 `do-while` 循环删了重写，甚至要改链表结构。


* **Lab 6 (裁判员问专业教练)**：
```c
// 1. 归还当前进程 (如果它还能跑)
if (current->state == PROC_RUNNABLE) {
    sched_class_enqueue(current);
}

// 2. 询问策略层：下一个选谁？
// 内核完全不关心 pick_next 内部是查链表还是查红黑树
next = sched_class_pick_next();

// 3. 将选中的进程从队列拿走
if (next != NULL) {
    sched_class_dequeue(next);
}

```


* **解耦分析**：
* `schedule` 函数变成了纯粹的**流程控制者**：它只负责协调“入队”、“挑选”、“出队”、“切换”这几个标准步骤。
* **算法的细节被完全隐藏**：
* 如果是 RR，`pick_next` 返回链表头。
* 如果是 Stride，`pick_next` 返回步长最小的节点。


* 这种设计使得 `schedule` 函数本身极其稳定，无论算法怎么变，这几行代码都不需要动。





### 总结：如何实现解耦？

Lab6 通过定义标准的接口 `struct sched_class` 实现了机制与策略的分离。

| 功能 | 机制 (Mechanism) - `kern/schedule/sched.c` | 策略 (Policy) - `kern/schedule/default_sched.c` |
| --- | --- | --- |
| **角色** | 经理 / 协调员 | 专家 / 执行者 |
| **关注点** | **何时**需要调度？(时钟中断、进程退出) | **谁**该下一个运行？(算法决策) |
| **唤醒** | 修改状态，调用 `enqueue` | 将进程插入具体的队列/堆结构 |
| **切换** | 保存/恢复上下文 (`proc_run`) | 无权干涉 |
| **数据结构** | 此时并不知道队列长什么样 | 维护具体的 `run_list` 或 `skew_heap` |

## 调度类的初始化流程：描述从内核启动到调度器初始化完成的完整流程，分析 default_sched_class 如何与调度器框架关联。


## 进程调度流程：绘制一个完整的进程调度流程图，包括：时钟中断触发、proc_tick 被调用、schedule() 函数执行、调度类各个函数的调用顺序。并解释 need_resched 标志位在调度过程中的作用


## 调度算法的切换机制：分析如果要添加一个新的调度算法（如stride），需要修改哪些代码？并解释为什么当前的设计使得切换调度算法变得容易。


# 练习2: 实现 Round Robin 调度算法（需要编码）

## 比较一个在lab5和lab6都有, 但是实现不同的函数, 说说为什么要做这个改动, 不做这个改动会出什么问题

核心区别在于：**Lab5 是硬编码的简单的遍历查找（FIFO），而 Lab6 引入了调度类（Scheduling Class）框架，实现了机制与策略的分离。**

以下是详细对比：

#### 1. 核心设计理念 (Architecture)

* **Lab5 (硬编码):**
* **策略与机制耦合：** 调度算法（如何选下一个进程）直接写死在 `schedule` 函数里。
* **算法单一：** 只能按照 `proc_list` 链表的顺序轮询查找（类似简单的轮转或 FIFO）。如果你想改用“优先级调度”，你必须重写整个 `schedule` 函数。


* **Lab6 (调度框架):**
* **策略与机制分离：** `schedule` 函数只负责流程控制（机制），具体的算法逻辑（策略）委托给 `sched_class` 接口（如 `enqueue`, `pick_next`）。
* **可扩展性：** 支持不同的调度算法（RR, Stride, MLFQ）。只需要替换 `sched_class` 指针，不需要修改 `schedule` 函数本身。



#### 2. 查找下一个进程的方式 (Search Strategy)

这是代码逻辑上最大的不同点。

* **Lab5: 全局链表  遍历**
```c
// 笨办法：拿着名单(proc_list)从当前位置一个个往下问
do {
    if ((le = list_next(le)) != &proc_list) {
        next = le2proc(le, list_link);
        if (next->state == PROC_RUNNABLE) { break; } // 找到一个醒着的就停下
    }
} while (le != last);

```


* 它是去**所有进程**的列表里“淘金”，跳过那些 Sleep 或 Zombie 的进程，找到第一个 Runnable 的。效率较低。


* **Lab6: 就绪队列  或  提取**
```c
// 聪明办法：直接问管理员(sched_class)要下一个是谁
if ((next = sched_class_pick_next()) != NULL) {
    sched_class_dequeue(next);
}

```


* 它维护了一个**专门的就绪队列 (Run Queue)**，里面**只**存放 Runnable 的进程。
* `pick_next` 不需要遍历无效进程，直接拿出来就行（对于 RR 算法就是拿队头），效率极高。



#### 3. 对当前进程 (`current`) 的处理

* **Lab5:**
* 并没有显式地把 `current` 放回某个队列。因为 Lab5 依赖的是全局 `proc_list`，`current` 本来就在那个链表里没动过。下次遍历自然还会轮到它（如果它没死也没睡的话）。


* **Lab6:**
* **显式入队：**


```c
if (current->state == PROC_RUNNABLE) {
    sched_class_enqueue(current);
}

```


* 如果当前进程只是时间片到了（状态还是 RUNNABLE），Lab6 会负责把它**重新加入**到就绪队列（通常是队尾）。这体现了 **“轮转”** 的思想：你用完了，去后面排队去。



#### 4. 总结对比表

| 特性 | Lab5 (用户程序阶段) | Lab6 (调度器阶段) |
| --- | --- | --- |
| **数据结构** | `proc_list` (包含所有状态的进程) | `run_queue` (只包含就绪进程) |
| **查找效率** |  (最坏情况遍历所有进程) |  (RR算法) 或  (优先级) |
| **灵活性** | 差 (修改算法需重写函数) | **极高** (只需实现新的 sched_class) |
| **当前进程** | 留在原地，靠遍历再次被选中 | 显式调用 `enqueue` 放回队尾 |
| **代码角色** | 既是裁判也是运动员 | 只是裁判，运动员由 `sched_class` 管理 |

## 描述你实现每个函数的具体思路和方法，解释为什么选择特定的链表操作方法。对每个实现函数的关键代码进行解释说明，并解释如何处理边界情况。

#### 1. 运行队列初始化 (Initialization)

初始化运行队列结构体，确保链表头指向自己，计数器清零。

```c
/*
 * RR_init: 初始化运行队列 rq
 * 设置 run_list 为空链表，proc_num 置 0
 */
static void
RR_init(struct run_queue *rq)
{
    // LAB6: 2312991
    
    // 初始化链表头节点 (prev 和 next 都指向自己)
    list_init(&rq->run_list);
    
    // 初始化进程计数器
    rq->proc_num = 0;
    
    // 初始化内存池指针 (可能是 Lab 特定需求，置空)
    rq->lab6_run_pool = NULL;
}

```

---

#### 2. 进程入队 (Enqueue)

当进程变为 Ready 状态（被唤醒）或时间片用完被抢占时，调用此函数将其加入队列**尾部**。

```c
/*
 * RR_enqueue: 将进程 proc 加入到运行队列 rq 的队尾
 * 1. 重置进程的时间片
 * 2. 将节点插入链表
 * 3. 更新队列元数据
 */
static void
RR_enqueue(struct run_queue *rq, struct proc_struct *proc)
{
    // LAB6: 2312991
    
    // 【关键】重置时间片
    // 每次进入就绪队列，都恢复其时间片为系统最大值 (max_time_slice)
    // 这样当它下次被调度时，又有满满的时间片可用
    proc->time_slice = rq->max_time_slice;
    
    // 记录该进程当前所属的运行队列
    proc->rq = rq;
    
    // 【关键】加入队尾
    // list_add_before 在头节点(run_list)之前插入，
    // 在双向循环链表中，head 的前一个节点就是 tail。
    list_add_before(&rq->run_list, &proc->run_link);
    
    // 队列进程数 +1
    rq->proc_num++;
}

```

---

#### 3. 进程出队 (Dequeue)

当进程被调度器选中（变成 Running）或者进程退出/阻塞时，将其从就绪队列移除。

```c
/*
 * RR_dequeue: 将进程 proc 从运行队列 rq 中移除
 */
static void
RR_dequeue(struct run_queue *rq, struct proc_struct *proc)
{
    // LAB6: 2312991
    
    // 从链表中删除该节点，并将其重新初始化 (prev/next 指向自己)
    list_del_init(&proc->run_link);
    
    // 维护队列计数器
    if (rq->proc_num > 0)
    {
        rq->proc_num--;
    }
    
    // 解除进程与队列的绑定关系
    proc->rq = NULL;
}

```

---

#### 4. 挑选下一个进程 (Pick Next)

RR 算法的核心调度策略：**先进先出 (FIFO)**。总是选择队列头部的进程。

```c
/*
 * RR_pick_next: 从运行队列队头选择一个进程
 * 返回对应的进程结构体指针，若队列为空则返回 NULL
 */
static struct proc_struct *
RR_pick_next(struct run_queue *rq)
{
    // LAB6: 2312991
    
    // 如果队列为空，没有进程可选
    if (list_empty(&rq->run_list))
    {
        return NULL;
    }
    
    // 获取链表的第一个节点 (head 的 next)
    // 这是一个 list_entry_t 指针
    list_entry_t *le = list_next(&rq->run_list);
    
    // 【关键】使用宏 le2proc 将链表节点转换为进程结构体指针
    // le2proc 利用 offsetof 原理，根据成员变量地址反推结构体首地址
    return le2proc(le, run_link);
}

```

---

#### 5. 时钟滴答处理 (Proc Tick)

每一次时钟中断（Tick）都会调用此函数，用于扣减当前进程的时间片。这是实现**抢占 (Preemption)** 的关键。

```c
/*
 * RR_proc_tick: 处理时钟中断事件
 * 检查当前进程时间片是否耗尽，若耗尽则标记需要调度
 */
static void
RR_proc_tick(struct run_queue *rq, struct proc_struct *proc)
{
    // LAB6: 2312991
    
    // 如果时间片还没用完，就减 1
    if (proc->time_slice > 0)
    {
        proc->time_slice--;
    }
    
    // 如果减完之后变成 0 了
    if (proc->time_slice == 0)
    {
        // 【关键】标记需要调度 (need_resched)
        // 内核会在适当的时候（如中断返回前）检查这个标志
        // 如果为 1，就会调用 schedule() 函数，把当前进程踢下去，
        // 从而实现“时间片轮转”。
        proc->need_resched = 1;
    }
}

```

## `make qemu` 结果
```bash
OpenSBI v0.4 (Jul  2 2019 11:53:53)
   ____                    _____ ____ _____
  / __ \                  / ____|  _ \_   _|
 | |  | |_ __   ___ _ __ | (___ | |_) || |
 | |  | | '_ \ / _ \ '_ \ \___ \|  _ < | |
 | |__| | |_) |  __/ | | |____) | |_) || |_
  \____/| .__/ \___|_| |_|_____/|____/_____|
        | |
        |_|

Platform Name          : QEMU Virt Machine
Platform HART Features : RV64ACDFIMSU
Platform Max HARTs     : 8
Current Hart           : 0
Firmware Base          : 0x80000000
Firmware Size          : 112 KB
Runtime SBI Version    : 0.1

PMP0: 0x0000000080000000-0x000000008001ffff (A)
PMP1: 0x0000000000000000-0xffffffffffffffff (A,R,W,X)
(THU.CST) os is loading ...

Special kernel symbols:
  entry  0xc020004a (virtual)
  etext  0xc0205978 (virtual)
  edata  0xc02b1238 (virtual)
  end    0xc02b5720 (virtual)
Kernel executable memory footprint: 726KB
DTB Init
HartID: 0
DTB Address: 0x82200000
Physical Memory from DTB:
  Base: 0x0000000080000000
  Size: 0x0000000008000000 (128 MB)
  End:  0x0000000087ffffff
DTB init completed
memory management: default_pmm_manager
physcial memory map:
  memory: 0x08000000, [0x80000000, 0x87ffffff].
vapaofset is 18446744070488326144
check_alloc_page() succeeded!
check_pgdir() succeeded!
check_boot_pgdir() succeeded!
use SLOB allocator
kmalloc_init() succeeded!
check_vma_struct() succeeded!
check_vmm() succeeded.
sched class: RR_scheduler
++ setup timer interrupts
kernel_execve: pid = 2, name = "priority".
set priority to 6
main: fork ok,now need to wait pids.
set priority to 1
set priority to 2
set priority to 3
set priority to 4
set priority to 5
100 ticks
100 ticks
child pid 3, acc 656000, time 2010
child pid 4, acc 668000, time 2010
child pid 5, acc 660000, time 2010
child pid 6, acc 656000, time 2010
child pid 7, acc 668000, time 2010
main: pid 0, acc 656000, time 2010
main: pid 4, acc 668000, time 2010
main: pid 5, acc 660000, time 2010
main: pid 6, acc 656000, time 2010
main: pid 7, acc 668000, time 2010
main: wait pids over
sched result: 1 1 1 1 1
all user-mode processes have quit.
init check memory pass.
kernel panic at kern/process/proc.c:553:
    initproc exit.
```



### 1. 调度现象：优先级失效与绝对公平

这是最显著的观察结果。

* **现象描述**：
尽管测试程序 `priority` 试图通过 `set priority` 将 5 个子进程（PID 3-7）的优先级分别设置为 1 到 5（优先级递增），但最终的运行结果显示，**所有子进程获得的 CPU 资源是完全一样的**。
* **证据支撑**：
请观察日志中的统计数据：
```text
child pid 3, acc 656000, time 2010
child pid 4, acc 668000, time 2010
child pid 5, acc 660000, time 2010
child pid 6, acc 656000, time 2010
child pid 7, acc 668000, time 2010

```


* **Time (时间片占用)**：所有 5 个进程的 `time` 竟然都是 **2010**。这说明调度器精确地给每个进程分配了相同数量的时间片，完全忽略了优先级的设置。
* **Acc (计算量)**：所有进程的计算量都在 660,000 左右，误差极小，说明它们执行进度的快慢也是一致的。


* **原因分析**：
日志第一行明确指出：`sched class: RR_scheduler`。
当前系统加载的是 **Round Robin（时间片轮转）** 调度器。RR 算法的设计初衷就是“公平”，它不维护优先级队列，也不查看进程的 priority 属性。它只负责让所有就绪进程排队，轮流使用 CPU。因此，**优先级设置在 RR 调度器下是无效的**。

### 2. 调度顺序：严格的 FIFO 轮转

观察日志中进程的输出顺序和 PID 的关系，可以推断出 RR 调度器内部队列的运作方式。

* **顺序描述**：
子进程的输出顺序严格按照 PID 递增：`PID 3 -> PID 4 -> PID 5 -> PID 6 -> PID 7`。
* **机制分析**：
1. **创建阶段**：主进程（PID 2）依次 fork 出子进程 3, 4, 5, 6, 7。
2. **入队顺序**：根据 RR 的 `enqueue` 逻辑（通常是添加到队尾），就绪队列（Run Queue）的初始顺序就是 `3 -> 4 -> 5 -> 6 -> 7`。
3. **执行阶段**：
* 调度器首先取出队头（PID 3）运行一个时间片。
* 时间片用完后，PID 3 被放回队尾。队列变为 `4 -> 5 -> 6 -> 7 -> 3`。
* 接着运行 PID 4...


4. **宏观结果**：
虽然微观上 CPU 在这 5 个进程间频繁快速切换，但由于它们执行的代码量（工作负载）完全相同，且 RR 保证了每轮大家得到的时间一样，所以它们几乎是**“齐头并进”**的。
最终，由于 PID 3 最先开始，在大家工作量一样的情况下，它也最先完成（或最先输出日志），紧接着是 4, 5, 6, 7。

## 分析 Round Robin 调度算法的优缺点，讨论如何调整时间片大小来优化系统性能，并解释为什么需要在 RR_proc_tick 中设置 need_resched 标志。


### 1. Round Robin (RR) 算法的优缺点分析

RR 算法的核心理念是**公平（Fairness）**与**分时（Time Sharing）**。

| 维度 | 优点 (Pros) | 缺点 (Cons) |
| --- | --- | --- |
| **公平性** | **最佳**。每个进程都有机会运行，不会出现因为优先级低而产生的“饥饿（Starvation）”现象。 | 这种“绝对公平”在某些场景下是缺点。因为它不区分任务的紧迫程度，紧急任务会被无关紧要的后台任务拖慢。 |
| **响应时间** | **适合交互式系统**。用户操作（如打字、点击）能得到较快的反馈，因为进程轮转很快。 | 如果进程数量非常多，轮转一圈的时间变长，响应时间也会显著下降。 |
| **周转时间** | 无 | **平均周转时间通常较差**。如果所有进程长度相同，RR 的表现几乎是最差的（所有进程几乎同时结束，而不是短作业先结束）。 |
| **实现难度** | **简单**。只需要一个 FIFO 队列和一个定时器，不需要复杂的算法（如红黑树）。 | 缺乏灵活性，难以适应复杂的实时系统需求。 |
| **CPU 利用率** | 较高（如果时间片设置得当）。 | 如果时间片过小，**上下文切换（Context Switch）** 的开销会极其巨大，导致 CPU 大部分时间在“空转”。 |

---

### 2. 时间片（Time Slice/Quantum）的调整与性能优化

时间片  的大小是 RR 算法性能的决定性因素。

#### 情况 A：时间片过小 (Too Small)

* **现象**：假设时间片为 1ms，而上下文切换需要 0.1ms。
* **后果**：CPU 花费  的时间在做切换动作，而不是执行用户代码。
* **系统表现**：吞吐量（Throughput）大幅下降，系统变慢，发热增加。

#### 情况 B：时间片过大 (Too Large)

* **现象**：假设时间片为 1000ms（1秒）。
* **后果**：RR 算法退化为 **FCFS (先来先服务)** 算法。
* **系统表现**：
* **响应性差**：如果我在用终端打字（需要 1ms CPU），前面排了一个需要跑 5秒的视频编码任务，我必须等它跑完一个时间片（1秒）才能看到字显示出来。这会造成严重的用户体验卡顿。



#### 优化策略：如何选择“刚刚好”的时间片？

通常遵循以下原则：

1. **覆盖绝大多数交互请求**：时间片应该略大于典型的交互式进程的 CPU 突发时间（通常在 10ms - 20ms 左右）。这样交互式进程可以在一个时间片内完成工作并主动释放 CPU，不需要被强制抢占。
2. **摊薄切换开销**：上下文切换的时间应该仅占时间片的 **1%** 以下。
* 如果切换耗时 10μs，时间片至少应设为 1ms 以上。


3. **现代 OS 的经验值**：Linux 或 Windows 的时间片通常在 **10ms 到 100ms** 之间动态调整。

---

### 3. 为什么在 `RR_proc_tick` 中设置 `need_resched`？

为什么在时钟中断里，当 `time_slice == 0` 时，不直接调用 `schedule()` 进行切换，而是仅仅设置一个 `need_resched = 1` 的标志位？

这涉及操作系统**中断处理**的核心设计原则。

#### 原因一：中断上下文 (Interrupt Context) 的限制

* `RR_proc_tick` 是在**时钟中断处理程序**（ISR, Interrupt Service Routine）中被调用的。
* **硬性规定**：中断处理程序必须**快进快出**。
* `schedule()` 是一个极其复杂和耗时的操作，它可能涉及：
* 获取复杂的锁（自旋锁、互斥锁）。
* 遍历运行队列。
* 保存/恢复大量的寄存器和内存状态。


* 如果在中断里直接做这些事，会长时间屏蔽其他中断，导致系统对鼠标、键盘或网络包失去响应。

#### 原因二：避免嵌套调度与死锁

* 如果在中断处理中直接切换进程，可能会导致**内核栈混乱**或者**死锁**。
* 例如，如果当前进程持有调度器的锁，然后被中断打断，中断处理程序试图再次获取锁去调度，就会导致死锁。

#### 机制：延迟调度 (Deferred Scheduling)

设置 `need_resched` 标志位实际上是一种**“延迟执行”**的请求。

1. **打标记**：在极短的 `tick` 中断里，内核只是简单地做个记号：“嗨，这个进程时间到了，**等会儿**把它换下去。”（耗时极短，纳秒级）。
2. **执行切换**：当 CPU 准备从中断（内核态）**返回用户态**的前一刻，内核会检查这个标志位。
* 如果 `need_resched == 1`，内核此时才真正调用 `schedule()`。
* 这个时刻已经是安全的、可抢占的时机了。





## 如果要实现优先级 RR 调度，你的代码需要如何修改？当前的实现是否支持多核调度？如果不支持，需要如何改进？

---

### 第一部分：如何实现优先级 RR 调度 (Priority Round Robin)

目前的实现是单队列的，所有进程无论优先级高低都在同一个 `run_list` 里排队。要支持优先级，最标准且高效的做法是采用 **多级队列（Multi-level Queue）**。

#### 1. 数据结构的修改

我们需要将原本的**一条链表**改为**一组链表数组**。假设系统支持 `MAX_PRIO` 个优先级（例如 0-63）。

```c
#define MAX_PRIO 64

struct run_queue {
    // 以前只有一条 list_entry_t run_list;
    // 现在变成一个数组，每个优先级对应一个队列
    list_entry_t run_list[MAX_PRIO]; 
    
    // 位图，用于快速查找哪个优先级的队列非空 (O(1) 查找的关键)
    // 如果优先级很多，可以用 uint64_t 或者位图数组
    uint64_t prio_bitmap; 

    unsigned int proc_num;
    int max_time_slice;
};

```

#### 2. `RR_enqueue` 的修改 (入队)

入队时，读取进程的 `priority`，将其放入对应的链表中，并设置位图。

```c
static void
Priority_RR_enqueue(struct run_queue *rq, struct proc_struct *proc)
{
    proc->time_slice = rq->max_time_slice;
    proc->rq = rq;
    
    // 安全检查，防止越界
    int prio = proc->priority;
    if (prio >= MAX_PRIO) prio = MAX_PRIO - 1;

    // 加入对应优先级的队尾
    list_add_before(&(rq->run_list[prio]), &(proc->run_link));
    
    // 标记位图：该优先级有进程了
    rq->prio_bitmap |= (1ULL << prio);
    
    rq->proc_num++;
}

```

#### 3. `RR_pick_next` 的修改 (O(1) 查找)

调度器需要总是选择**当前存在的最高优先级**队列中的进程。

```c
static struct proc_struct *
Priority_RR_pick_next(struct run_queue *rq)
{
    if (rq->proc_num == 0) return NULL;

    // 使用位操作找到最高优先级的队列（假设高位代表高优先级，或者低位代表高优先级，看具体定义）
    // 这里假设 priority 数值越小，优先级越高 (0是最高)
    // lowbit 最低有效位的位置
    int highest_prio = lowbit(rq->prio_bitmap);

    list_entry_t *le = list_next(&(rq->run_list[highest_prio]));
    return le2proc(le, run_link);
}

```

#### 4. `RR_dequeue` 的修改

出队时，如果该优先级队列空了，需要清除位图。

```c
static void
Priority_RR_dequeue(struct run_queue *rq, struct proc_struct *proc)
{
    int prio = proc->priority;
    list_del_init(&(proc->run_link));
    rq->proc_num--;

    // 如果该优先级队列空了，清除位图对应位
    if (list_empty(&(rq->run_list[prio]))) {
        rq->prio_bitmap &= ~(1ULL << prio);
    }
}

```

> **注意：饥饿问题 (Starvation)**
> 这种严格优先级的 RR 会导致低优先级进程永远无法运行（Starvation）。解决方案是引入**老化机制 (Aging)**：在 `proc_tick` 中，每隔一段时间提升低优先级进程的优先级，或者改用**多级反馈队列 (MLFQ)**。

---

### 第二部分：当前实现是否支持多核调度 (SMP)？

**结论：不支持。**

如果不加修改直接在多核 CPU 上运行现在的代码，内核会迅速崩溃（Panic）或死锁。

#### 为什么不支持？

1. **全局共享数据无锁保护：**
代码中使用了一个全局静态变量 `static struct run_queue __rq;`。在多核环境下，所有 CPU 共享这同一个队列。
* CPU A 正在 `enqueue`（修改链表指针）。
* CPU B 同时在 `pick_next`（遍历链表）。
* **结果：** 链表指针错乱，导致内存访问错误。


2. **`local_intr_save` 的局限性：**
目前的保护机制是 `local_intr_save(intr_flag)`。
* 这只能关闭**当前 CPU** 的中断。
* 它**无法阻止其他 CPU** 执行代码。
* 在单核中，关中断就能保证原子性；但在多核中，关中断只能防止被中断打断，防止不了其他 CPU 的并发访问。



---

### 第三部分：如何改进以支持多核？

要支持 SMP，通常有两种方案。现代操作系统（如 Linux）通常结合使用。

#### 方案 A：每个 CPU 一个运行队列 (Per-CPU Run Queue) —— **推荐**

这是最主流的做法，减少了锁竞争（Contention），提高了缓存局部性（Cache Locality）。

**1. 数据结构改造**

```c
// 不再是单例，而是数组
static struct run_queue __rq[NCPU]; 

// 获取当前 CPU 的 ID 并返回对应的队列
struct run_queue* get_cpu_rq() {
    int cpu_id = get_current_cpu_id(); 
    return &__rq[cpu_id];
}

```

**2. 引入自旋锁 (Spinlock)**
即使是 Per-CPU 队列，也需要锁。因为有时候 CPU A 需要唤醒在 CPU B 上睡眠的进程，或者进行负载均衡（偷任务）。

```c
struct run_queue {
    spinlock_t lock; // 新增：自旋锁
    list_entry_t run_list;
    // ...
};

```

**3. 修改 `schedule` 和 `wakeup`**

```c
void schedule(void)
{
    struct run_queue *rq = get_cpu_rq();
    
    // 必须加锁，因为可能发生负载均衡器来偷任务
    spin_lock(&rq->lock); 
    
    // ... 原有的 pick_next, dequeue 逻辑 ...
    
    spin_unlock(&rq->lock);
    
    // 真正的上下文切换 switch_to 通常在锁释放后或特殊处理
}

```

#### 方案 B：全局队列 + 全局大锁 (Big Lock) —— **简单但性能差**

如果不想大改数据结构，可以保留一个全局 `__rq`，但在访问它之前必须获取一个全局自旋锁。

```c
static struct run_queue __rq;
spinlock_t global_sched_lock;

void schedule() {
    spin_lock(&global_sched_lock); // 锁住整个调度器
    // ... 所有的 enqueue/pick/dequeue ...
    spin_unlock(&global_sched_lock);
}

```

* **缺点：** 随着 CPU 核心数增加，锁竞争会极其严重，性能急剧下降。这通常只用于教学 OS 的早期阶段。



# 扩展练习 Challenge 1: 实现 Stride Scheduling 调度算法（需要编码）

# 扩展练习 Challenge 2 ：在ucore上实现尽可能多的各种基本调度算法(FIFO, SJF,...)，并设计各种测试用例，能够定量地分析出各种调度算法在各种指标上的差异，说明调度算法的适用范围。